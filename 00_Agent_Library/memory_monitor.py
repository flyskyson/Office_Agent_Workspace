#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®°å¿†ç³»ç»Ÿæ•ˆç‡ç›‘æ§

ç›‘æ§è®°å¿†ç³»ç»Ÿçš„æ€§èƒ½æŒ‡æ ‡ï¼š
1. åŠ è½½æ—¶é—´
2. æœç´¢æ—¶é—´
3. è®°å¿†å¤§å°
4. è®°å½•æ•°é‡

å½“æŒ‡æ ‡è¶…è¿‡é˜ˆå€¼æ—¶å‘å‡ºè­¦å‘Šï¼Œå¹¶æä¾›ä¼˜åŒ–å»ºè®®ã€‚

ä½œè€…: Claude Code
æ—¥æœŸ: 2026-01-15
"""

import sys
import json
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any

# Windows ç»ˆç«¯ç¼–ç ä¿®å¤
if sys.platform == 'win32':
    try:
        import codecs
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')
    except:
        pass

# æ·»åŠ è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from claude_memory import ClaudeMemory


# ============================================================================
# æ•ˆç‡ç›‘æ§å™¨
# ============================================================================

class MemoryMonitor:
    """è®°å¿†ç³»ç»Ÿæ•ˆç‡ç›‘æ§å™¨"""

    # æ€§èƒ½é˜ˆå€¼
    THRESHOLDS = {
        'load_time_ms': 100,        # åŠ è½½æ—¶é—´é˜ˆå€¼ï¼ˆæ¯«ç§’ï¼‰
        'search_time_ms': 50,       # æœç´¢æ—¶é—´é˜ˆå€¼ï¼ˆæ¯«ç§’ï¼‰
        'memory_size_mb': 1.0,      # è®°å¿†å¤§å°é˜ˆå€¼ï¼ˆMBï¼‰
        'total_records': 100,       # æ€»è®°å½•æ•°é˜ˆå€¼
        'high_priority_ratio': 0.3  # é«˜ä¼˜å…ˆçº§è®°å½•æ¯”ä¾‹é˜ˆå€¼
    }

    def __init__(self, workspace_root: Path = None):
        self.memory = ClaudeMemory(workspace_root)
        self.workspace_root = workspace_root or Path.cwd()
        self.memory_dir = self.workspace_root / "06_Learning_Journal" / "claude_memory"

    def monitor_all(self) -> Dict[str, Any]:
        """ç›‘æ§æ‰€æœ‰æŒ‡æ ‡"""
        results = {}

        # 1. åŠ è½½æ—¶é—´æµ‹è¯•
        results['load_time'] = self._test_load_performance()

        # 2. æœç´¢æ—¶é—´æµ‹è¯•
        results['search_time'] = self._test_search_performance()

        # 3. è®°å¿†å¤§å°ç»Ÿè®¡
        results['memory_size'] = self._get_memory_size()

        # 4. è®°å½•æ•°é‡ç»Ÿè®¡
        results['record_count'] = self._get_record_count()

        # 5. ç”ŸæˆæŠ¥å‘Š
        results['report'] = self._generate_report(results)

        # 6. ä¼˜åŒ–å»ºè®®
        results['recommendations'] = self._get_recommendations(results)

        return results

    def _test_load_performance(self) -> Dict[str, Any]:
        """æµ‹è¯•åŠ è½½æ€§èƒ½"""
        start = time.time()

        # æ¨¡æ‹ŸåŠ è½½æ‰€æœ‰è®°å¿†æ–‡ä»¶
        for file in self.memory_dir.glob("*.json"):
            with open(file, 'r', encoding='utf-8') as f:
                json.load(f)

        load_time = time.time() - start
        load_time_ms = load_time * 1000

        return {
            'time_ms': round(load_time_ms, 2),
            'time_seconds': round(load_time, 4),
            'status': 'OK' if load_time_ms < self.THRESHOLDS['load_time_ms'] else 'WARNING',
            'threshold_ms': self.THRESHOLDS['load_time_ms']
        }

    def _test_search_performance(self) -> Dict[str, Any]:
        """æµ‹è¯•æœç´¢æ€§èƒ½"""
        # æµ‹è¯•ä¸åŒæœç´¢æ–¹å¼çš„æ€§èƒ½
        search_tests = []

        # æµ‹è¯•1: ä¸»é¢˜æœç´¢
        start = time.time()
        contexts = self.memory.recall("è§’è‰²å®šä¹‰")
        search_time = (time.time() - start) * 1000
        search_tests.append({
            'type': 'topic_search',
            'query': 'è§’è‰²å®šä¹‰',
            'time_ms': round(search_time, 2),
            'results': len(contexts)
        })

        # æµ‹è¯•2: å…¨å±€æœç´¢
        start = time.time()
        results = self.memory.store.search_all_contexts("è®°å¿†", limit=10)
        search_time = (time.time() - start) * 1000
        search_tests.append({
            'type': 'global_search',
            'query': 'è®°å¿†',
            'time_ms': round(search_time, 2),
            'results': len(results)
        })

        # æµ‹è¯•3: é«˜ä¼˜å…ˆçº§æ£€ç´¢
        start = time.time()
        high_priority = self.memory.recall_high_priority()
        search_time = (time.time() - start) * 1000
        search_tests.append({
            'type': 'high_priority',
            'query': 'N/A',
            'time_ms': round(search_time, 2),
            'results': len(high_priority)
        })

        # è®¡ç®—å¹³å‡æœç´¢æ—¶é—´
        avg_time = sum(t['time_ms'] for t in search_tests) / len(search_tests)

        return {
            'tests': search_tests,
            'avg_time_ms': round(avg_time, 2),
            'status': 'OK' if avg_time < self.THRESHOLDS['search_time_ms'] else 'WARNING',
            'threshold_ms': self.THRESHOLDS['search_time_ms']
        }

    def _get_memory_size(self) -> Dict[str, Any]:
        """è·å–è®°å¿†å¤§å°"""
        total_size = 0
        file_sizes = {}

        for file in self.memory_dir.glob("*.json"):
            size = file.stat().st_size
            total_size += size
            file_sizes[file.name] = {
                'bytes': size,
                'kb': round(size / 1024, 2)
            }

        total_size_mb = total_size / (1024 * 1024)

        return {
            'total_bytes': total_size,
            'total_kb': round(total_size / 1024, 2),
            'total_mb': round(total_size_mb, 3),
            'file_sizes': file_sizes,
            'status': 'OK' if total_size_mb < self.THRESHOLDS['memory_size_mb'] else 'WARNING',
            'threshold_mb': self.THRESHOLDS['memory_size_mb']
        }

    def _get_record_count(self) -> Dict[str, Any]:
        """è·å–è®°å½•æ•°é‡"""
        stats = self.memory.get_memory_stats()

        total = (
            stats['total_contexts'] +
            stats['total_decisions'] +
            stats['total_conversations']
        )

        high_priority_count = len(self.memory.recall_high_priority())
        high_priority_ratio = high_priority_count / max(total, 1)

        return {
            'contexts': stats['total_contexts'],
            'decisions': stats['total_decisions'],
            'conversations': stats['total_conversations'],
            'total': total,
            'high_priority_count': high_priority_count,
            'high_priority_ratio': round(high_priority_ratio, 2),
            'status': 'OK' if total < self.THRESHOLDS['total_records'] else 'WARNING',
            'threshold': self.THRESHOLDS['total_records']
        }

    def _generate_report(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        report_lines = [
            "\n" + "=" * 70,
            "ğŸ“Š è®°å¿†ç³»ç»Ÿæ•ˆç‡ç›‘æ§æŠ¥å‘Š",
            "=" * 70,
            f"â° æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            ""
        ]

        # åŠ è½½æ€§èƒ½
        load = results['load_time']
        status_icon = "âœ…" if load['status'] == 'OK' else "âš ï¸"
        report_lines.extend([
            f"âš¡ åŠ è½½æ€§èƒ½",
            f"   æ—¶é—´: {load['time_ms']} ms / {load['threshold_ms']} ms {status_icon}",
            f"   çŠ¶æ€: {load['status']}",
            ""
        ])

        # æœç´¢æ€§èƒ½
        search = results['search_time']
        status_icon = "âœ…" if search['status'] == 'OK' else "âš ï¸"
        report_lines.extend([
            f"ğŸ” æœç´¢æ€§èƒ½",
            f"   å¹³å‡æ—¶é—´: {search['avg_time_ms']} ms / {search['threshold_ms']} ms {status_icon}",
            ""
        ])
        for test in search['tests']:
            report_lines.append(
                f"   - {test['type']}: {test['time_ms']} ms ({test['results']} ç»“æœ)"
            )
        report_lines.append("")

        # è®°å¿†å¤§å°
        size = results['memory_size']
        status_icon = "âœ…" if size['status'] == 'OK' else "âš ï¸"
        report_lines.extend([
            f"ğŸ’¾ è®°å¿†å¤§å°",
            f"   æ€»å¤§å°: {size['total_kb']} KB ({size['total_mb']} MB) {status_icon}",
            f"   é˜ˆå€¼: {size['threshold_mb']} MB",
            ""
        ])

        # è®°å½•æ•°é‡
        count = results['record_count']
        status_icon = "âœ…" if count['status'] == 'OK' else "âš ï¸"
        report_lines.extend([
            f"ğŸ“ è®°å½•æ•°é‡",
            f"   æ€»è®°å½•: {count['total']} / {count['threshold']} {status_icon}",
            f"   - ä¸Šä¸‹æ–‡: {count['contexts']}",
            f"   - å†³ç­–: {count['decisions']}",
            f"   - å¯¹è¯: {count['conversations']}",
            f"   - é«˜ä¼˜å…ˆçº§: {count['high_priority_count']} ({count['high_priority_ratio']*100:.0f}%)",
            ""
        ])

        # æ€»ä½“è¯„ä¼°
        warnings = [
            results['load_time']['status'],
            results['search_time']['status'],
            results['memory_size']['status'],
            results['record_count']['status']
        ]

        if all(w == 'OK' for w in warnings):
            report_lines.extend([
                "ğŸ‰ æ€»ä½“è¯„ä¼°: âœ… æ‰€æœ‰æŒ‡æ ‡æ­£å¸¸",
                "   è®°å¿†ç³»ç»Ÿè¿è¡Œè‰¯å¥½ï¼Œæ— éœ€ä¼˜åŒ–ã€‚"
            ])
        else:
            warning_count = sum(1 for w in warnings if w == 'WARNING')
            report_lines.extend([
                f"âš ï¸ æ€»ä½“è¯„ä¼°: {warning_count} ä¸ªæŒ‡æ ‡éœ€è¦å…³æ³¨",
                "   å»ºè®®æŸ¥çœ‹ä¼˜åŒ–å»ºè®®éƒ¨åˆ†ã€‚"
            ])

        report_lines.append("=" * 70)

        return "\n".join(report_lines)

    def _get_recommendations(self, results: Dict[str, Any]) -> List[str]:
        """è·å–ä¼˜åŒ–å»ºè®®"""
        recommendations = []

        # æ£€æŸ¥åŠ è½½æ—¶é—´
        if results['load_time']['status'] == 'WARNING':
            recommendations.append(
                "âš ï¸ åŠ è½½æ—¶é—´è¿‡é•¿ï¼Œå»ºè®®:\n"
                "   1. æ·»åŠ è®°å¿†ç´¢å¼•ç³»ç»Ÿ\n"
                "   2. å½’æ¡£æ—§è®°å¿†åˆ°å•ç‹¬æ–‡ä»¶\n"
                "   3. è€ƒè™‘ä½¿ç”¨äºŒè¿›åˆ¶æ ¼å¼ï¼ˆå¦‚pickleï¼‰"
            )

        # æ£€æŸ¥æœç´¢æ—¶é—´
        if results['search_time']['status'] == 'WARNING':
            recommendations.append(
                "âš ï¸ æœç´¢æ—¶é—´è¿‡é•¿ï¼Œå»ºè®®:\n"
                "   1. å®ç°è®°å¿†ç´¢å¼•ï¼ˆæŒ‰ä¸»é¢˜ã€æ ‡ç­¾ã€ä¼˜å…ˆçº§ï¼‰\n"
                "   2. ä½¿ç”¨å­—å…¸æŸ¥æ‰¾æ›¿ä»£çº¿æ€§æœç´¢\n"
                "   3. é™åˆ¶æœç´¢ç»“æœæ•°é‡"
            )

        # æ£€æŸ¥è®°å¿†å¤§å°
        if results['memory_size']['status'] == 'WARNING':
            recommendations.append(
                "âš ï¸ è®°å¿†å¤§å°è¿‡å¤§ï¼Œå»ºè®®:\n"
                "   1. æ¸…ç†è¿‡æœŸè®°å¿†ï¼ˆ90å¤©ä»¥ä¸Šï¼‰\n"
                "   2. å½’æ¡£æ—§è®°å¿†åˆ° 02_Project_Archive\n"
                "   3. åªä¿ç•™é«˜ä¼˜å…ˆçº§å’Œæœ€è¿‘è®°å¿†"
            )

        # æ£€æŸ¥è®°å½•æ•°é‡
        if results['record_count']['status'] == 'WARNING':
            recommendations.append(
                "âš ï¸ è®°å½•æ•°é‡è¿‡å¤šï¼Œå»ºè®®:\n"
                "   1. è®¾ç½®è®°å¿†ä¼˜å…ˆçº§ï¼Œåªä¿ç•™é‡è¦çš„\n"
                "   2. å®šæœŸæ¸…ç†ä½ä¼˜å…ˆçº§è®°å½•\n"
                "   3. å®ç°è®°å¿†åˆ†çº§å­˜å‚¨ç³»ç»Ÿ"
            )

        # æ£€æŸ¥é«˜ä¼˜å…ˆçº§æ¯”ä¾‹
        if results['record_count']['high_priority_ratio'] < 0.1:
            recommendations.append(
                "ğŸ’¡ é«˜ä¼˜å…ˆçº§è®°å¿†è¾ƒå°‘ï¼Œå»ºè®®:\n"
                "   1. å°†é‡è¦çš„è§’è‰²å®šä¹‰ã€ç”¨æˆ·åå¥½æ ‡è®°ä¸ºé«˜ä¼˜å…ˆçº§\n"
                "   2. å®šæœŸå®¡æŸ¥è®°å¿†ä¼˜å…ˆçº§\n"
                "   3. ç¡®ä¿å…³é”®ä¿¡æ¯ä¸ä¼šä¸¢å¤±"
            )

        if not recommendations:
            recommendations.append("âœ… æ‰€æœ‰æŒ‡æ ‡æ­£å¸¸ï¼Œæš‚æ— ä¼˜åŒ–å»ºè®®ã€‚")

        return recommendations

    def save_performance_history(self, results: Dict[str, Any]):
        """ä¿å­˜æ€§èƒ½å†å²"""
        history_file = self.memory_dir / "performance_history.jsonl"

        # è®°å½•æœ¬æ¬¡æ€§èƒ½æ•°æ®
        record = {
            'timestamp': datetime.now().isoformat(),
            'load_time_ms': results['load_time']['time_ms'],
            'search_time_ms': results['search_time']['avg_time_ms'],
            'memory_size_kb': results['memory_size']['total_kb'],
            'total_records': results['record_count']['total'],
            'warnings': [
                results['load_time']['status'],
                results['search_time']['status'],
                results['memory_size']['status'],
                results['record_count']['status']
            ]
        }

        # è¿½åŠ åˆ°å†å²æ–‡ä»¶
        with open(history_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(record, ensure_ascii=False) + '\n')

        return history_file

    def plot_performance_trend(self):
        """ç»˜åˆ¶æ€§èƒ½è¶‹åŠ¿å›¾ï¼ˆéœ€è¦matplotlibï¼‰"""
        try:
            import matplotlib.pyplot as plt
            import matplotlib.dates as mdates
        except ImportError:
            print("âš ï¸ éœ€è¦å®‰è£… matplotlib: pip install matplotlib")
            return

        history_file = self.memory_dir / "performance_history.jsonl"

        if not history_file.exists():
            print("âš ï¸ æš‚æ— å†å²æ•°æ®")
            return

        # è¯»å–å†å²æ•°æ®
        records = []
        with open(history_file, 'r', encoding='utf-8') as f:
            for line in f:
                records.append(json.loads(line))

        if len(records) < 2:
            print("âš ï¸ æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç»˜åˆ¶è¶‹åŠ¿å›¾")
            return

        # å‡†å¤‡æ•°æ®
        timestamps = [datetime.fromisoformat(r['timestamp']) for r in records]
        load_times = [r['load_time_ms'] for r in records]
        search_times = [r['search_time_ms'] for r in records]
        memory_sizes = [r['memory_size_kb'] for r in records]

        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(3, 1, figsize=(12, 10))
        fig.suptitle('è®°å¿†ç³»ç»Ÿæ€§èƒ½è¶‹åŠ¿', fontsize=16)

        # åŠ è½½æ—¶é—´è¶‹åŠ¿
        axes[0].plot(timestamps, load_times, 'b-o', label='åŠ è½½æ—¶é—´')
        axes[0].axhline(y=self.THRESHOLDS['load_time_ms'], color='r', linestyle='--', label='é˜ˆå€¼')
        axes[0].set_ylabel('æ—¶é—´ (ms)')
        axes[0].set_title('åŠ è½½æ€§èƒ½')
        axes[0].legend()
        axes[0].grid(True)

        # æœç´¢æ—¶é—´è¶‹åŠ¿
        axes[1].plot(timestamps, search_times, 'g-o', label='æœç´¢æ—¶é—´')
        axes[1].axhline(y=self.THRESHOLDS['search_time_ms'], color='r', linestyle='--', label='é˜ˆå€¼')
        axes[1].set_ylabel('æ—¶é—´ (ms)')
        axes[1].set_title('æœç´¢æ€§èƒ½')
        axes[1].legend()
        axes[1].grid(True)

        # è®°å¿†å¤§å°è¶‹åŠ¿
        axes[2].plot(timestamps, memory_sizes, 'm-o', label='è®°å¿†å¤§å°')
        axes[2].axhline(y=self.THRESHOLDS['memory_size_mb'] * 1024, color='r', linestyle='--', label='é˜ˆå€¼')
        axes[2].set_ylabel('å¤§å° (KB)')
        axes[2].set_xlabel('æ—¶é—´')
        axes[2].set_title('è®°å¿†å¤§å°')
        axes[2].legend()
        axes[2].grid(True)

        # æ ¼å¼åŒ–xè½´
        for ax in axes:
            ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))
            plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)

        plt.tight_layout()

        # ä¿å­˜å›¾è¡¨
        output_file = self.memory_dir / "performance_trend.png"
        plt.savefig(output_file, dpi=100, bbox_inches='tight')
        print(f"âœ… è¶‹åŠ¿å›¾å·²ä¿å­˜: {output_file}")

        plt.close()


# ============================================================================
# ä¾¿æ·å‡½æ•°
# ============================================================================

def monitor_performance(show_recommendations: bool = True) -> Dict[str, Any]:
    """ç›‘æ§æ€§èƒ½ï¼ˆä¾¿æ·å‡½æ•°ï¼‰"""
    monitor = MemoryMonitor()
    results = monitor.monitor_all()

    # æ‰“å°æŠ¥å‘Š
    print(results['report'])

    # æ‰“å°å»ºè®®
    if show_recommendations:
        if any(w == 'WARNING' for w in [
            results['load_time']['status'],
            results['search_time']['status'],
            results['memory_size']['status'],
            results['record_count']['status']
        ]):
            print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
            print("-" * 70)
            for i, rec in enumerate(results['recommendations'], 1):
                print(f"\n{i}. {rec}")
        else:
            print("\nâœ… ç³»ç»Ÿè¿è¡Œè‰¯å¥½ï¼Œæ— éœ€ä¼˜åŒ–ã€‚")

    # ä¿å­˜å†å²
    monitor.save_performance_history(results)

    return results


# ============================================================================
# å‘½ä»¤è¡Œå…¥å£
# ============================================================================

def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description='è®°å¿†ç³»ç»Ÿæ•ˆç‡ç›‘æ§')
    parser.add_argument('--plot', '-p', action='store_true',
                       help='ç»˜åˆ¶æ€§èƒ½è¶‹åŠ¿å›¾')
    parser.add_argument('--quiet', '-q', action='store_true',
                       help='å®‰é™æ¨¡å¼')

    args = parser.parse_args()

    # ç›‘æ§æ€§èƒ½
    results = monitor_performance(show_recommendations=not args.quiet)

    # ç»˜åˆ¶è¶‹åŠ¿å›¾
    if args.plot:
        monitor = MemoryMonitor()
        monitor.plot_performance_trend()

    return 0


if __name__ == "__main__":
    sys.exit(main())
