#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šAgentç³»ç»ŸåŸå‹ - æ™ºèƒ½æ–‡æ¡£å¤„ç†å›¢é˜Ÿ

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å¤šä¸ªä¸“é—¨çš„Agentåä½œå®Œæˆä»»åŠ¡:
- åè°ƒè€…(Coordinator): åˆ†é…ä»»åŠ¡å’Œåè°ƒå·¥ä½œ
- åˆ†æå¸ˆ(Analyst): åˆ†ææ–‡æ¡£å†…å®¹å’Œç»“æ„
- å¤„ç†å™¨(Processor): æ‰§è¡Œå…·ä½“çš„æ–‡æ¡£å¤„ç†æ“ä½œ
- å®¡æŸ¥å¸ˆ(Reviewer): å®¡æŸ¥ç»“æœå¹¶ç”ŸæˆæŠ¥å‘Š

åŸºäºç°æœ‰çš„ WorkflowEngine æ¡†æ¶

ä½œè€…: Claude Code
æ—¥æœŸ: 2026-01-15
"""

import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional

# Windows ç»ˆç«¯ç¼–ç ä¿®å¤
if sys.platform == 'win32':
    try:
        import codecs
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')
    except:
        pass

# å¯¼å…¥å·¥ä½œæµå¼•æ“
sys.path.insert(0, str(Path(__file__).parent))
from workflow_engine import (
    WorkflowGraph, Node, State, WorkflowStatus,
    ConditionalEdge, Edge, END
)


# ============================================================================
# Agent åŸºç±»
# ============================================================================

class BaseAgent(Node):
    """AgentåŸºç±»"""

    def __init__(self, name: str, role: str, expertise: List[str]):
        super().__init__(name, f"{role} - {', '.join(expertise)}")
        self.role = role
        self.expertise = expertise
        self.agent_type = self.__class__.__name__

    def log(self, message: str, level: str = "INFO"):
        """è®°å½•æ—¥å¿—"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"[{timestamp}] [{self.agent_type}] {message}")

    def execute(self, state: State) -> State:
        """æ‰§è¡ŒAgentä»»åŠ¡"""
        self.log(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡: {self.name}")
        self.log(f"å½“å‰çŠ¶æ€: {state['metadata'].get('phase', 'unknown')}")

        try:
            result = self.process(state)
            self.log(f"ä»»åŠ¡å®Œæˆ: {self.name}")
            return result
        except Exception as e:
            self.log(f"ä»»åŠ¡å¤±è´¥: {str(e)}", "ERROR")
            state['errors'].append(f"{self.name}: {str(e)}")
            return state

    def process(self, state: State) -> State:
        """å…·ä½“çš„å¤„ç†é€»è¾‘ï¼Œç”±å­ç±»å®ç°"""
        raise NotImplementedError


# ============================================================================
# å…·ä½“Agentå®ç°
# ============================================================================

class CoordinatorAgent(BaseAgent):
    """åè°ƒè€…Agent - è´Ÿè´£ä»»åŠ¡åˆ†é…å’Œå·¥ä½œæµåè°ƒ"""

    def __init__(self):
        super().__init__(
            name="coordinator",
            role="é¡¹ç›®åè°ƒè€…",
            expertise=["ä»»åŠ¡è§„åˆ’", "èµ„æºåˆ†é…", "è¿›åº¦è·Ÿè¸ª"]
        )

    def process(self, state: State) -> State:
        """åè°ƒæ•´ä¸ªå·¥ä½œæµç¨‹"""
        data = state['data']

        # åˆå§‹åŒ–ä»»åŠ¡
        if 'tasks' not in data:
            data['tasks'] = []
            data['current_task_index'] = 0

            # åˆ†æè¾“å…¥ï¼Œåˆ›å»ºä»»åŠ¡åˆ—è¡¨
            input_text = data.get('input_text', '')
            if input_text:
                # ç®€å•çš„åˆ†è¯å’Œåˆ†æ
                words = input_text.split()
                data['total_words'] = len(words)
                data['tasks'] = [
                    {'id': 1, 'type': 'analyze', 'description': 'åˆ†ææ–‡æ¡£ç»“æ„'},
                    {'id': 2, 'type': 'extract', 'description': 'æå–å…³é”®ä¿¡æ¯'},
                    {'id': 3, 'type': 'process', 'description': 'å¤„ç†å’Œä¼˜åŒ–'},
                    {'id': 4, 'type': 'review', 'description': 'å®¡æŸ¥å’ŒæŠ¥å‘Š'}
                ]

            self.log(f"åˆ›å»ºäº† {len(data['tasks'])} ä¸ªä»»åŠ¡")
            state['metadata']['phase'] = 'planning_complete'
            state['metadata']['progress'] = '0%'

        return state


class AnalystAgent(BaseAgent):
    """åˆ†æå¸ˆAgent - è´Ÿè´£æ–‡æ¡£å†…å®¹åˆ†æ"""

    def __init__(self):
        super().__init__(
            name="analyst",
            role="æ–‡æ¡£åˆ†æå¸ˆ",
            expertise=["å†…å®¹åˆ†æ", "ç»“æ„è¯†åˆ«", "å…³é”®è¯æå–"]
        )

    def process(self, state: State) -> State:
        """åˆ†ææ–‡æ¡£å†…å®¹"""
        data = state['data']

        # è·å–è¾“å…¥æ–‡æœ¬
        text = data.get('input_text', '')

        if not text:
            state['errors'].append("æ²¡æœ‰å¯åˆ†æçš„æ–‡æœ¬")
            return state

        # æ‰§è¡Œåˆ†æ
        analysis = {
            'word_count': len(text.split()),
            'char_count': len(text),
            'line_count': text.count('\n') + 1,
            'avg_word_length': sum(len(word) for word in text.split()) / max(len(text.split()), 1),
            'keywords': self._extract_keywords(text),
            'sentiment': self._analyze_sentiment(text),
            'complexity': self._assess_complexity(text)
        }

        data['analysis'] = analysis
        state['metadata']['phase'] = 'analysis_complete'
        state['metadata']['progress'] = '25%'

        self.log(f"åˆ†æå®Œæˆ: {analysis['word_count']} è¯, {analysis['line_count']} è¡Œ")
        self.log(f"å…³é”®è¯: {', '.join(analysis['keywords'][:5])}")

        return state

    def _extract_keywords(self, text: str) -> List[str]:
        """ç®€å•çš„å…³é”®è¯æå–"""
        # åœç”¨è¯
        stopwords = {'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€',
                    'a', 'an', 'the', 'is', 'are', 'was', 'were', 'be', 'been', 'being'}

        # åˆ†è¯å¹¶è¿‡æ»¤
        words = [w for w in text.split() if len(w) > 2 and w.lower() not in stopwords]

        # ç»Ÿè®¡è¯é¢‘
        freq = {}
        for word in words:
            word_lower = word.lower()
            freq[word_lower] = freq.get(word_lower, 0) + 1

        # è¿”å›å‰10ä¸ªé«˜é¢‘è¯
        sorted_words = sorted(freq.items(), key=lambda x: x[1], reverse=True)
        return [word for word, count in sorted_words[:10]]

    def _analyze_sentiment(self, text: str) -> str:
        """ç®€å•çš„æƒ…æ„Ÿåˆ†æ"""
        positive_words = {'å¥½', 'ä¼˜ç§€', 'æˆåŠŸ', 'å–œæ¬¢', 'æ£’', 'excellent', 'good', 'great', 'love'}
        negative_words = {'å·®', 'å¤±è´¥', 'è®¨åŒ', 'ç³Ÿç³•', 'bad', 'fail', 'hate', 'terrible'}

        text_lower = text.lower()
        positive_count = sum(1 for word in positive_words if word in text_lower)
        negative_count = sum(1 for word in negative_words if word in text_lower)

        if positive_count > negative_count:
            return "ç§¯æ"
        elif negative_count > positive_count:
            return "æ¶ˆæ"
        else:
            return "ä¸­æ€§"

    def _assess_complexity(self, text: str) -> str:
        """è¯„ä¼°æ–‡æœ¬å¤æ‚åº¦"""
        words = text.split()
        avg_length = sum(len(w) for w in words) / max(len(words), 1)

        if avg_length < 4:
            return "ç®€å•"
        elif avg_length < 6:
            return "ä¸­ç­‰"
        else:
            return "å¤æ‚"


class ProcessorAgent(BaseAgent):
    """å¤„ç†å™¨Agent - è´Ÿè´£æ–‡æ¡£å¤„ç†å’Œä¼˜åŒ–"""

    def __init__(self):
        super().__init__(
            name="processor",
            role="æ–‡æ¡£å¤„ç†å™¨",
            expertise=["æ–‡æœ¬ä¼˜åŒ–", "æ ¼å¼æ•´ç†", "å†…å®¹å¢å¼º"]
        )

    def process(self, state: State) -> State:
        """å¤„ç†å’Œä¼˜åŒ–æ–‡æ¡£"""
        data = state['data']

        text = data.get('input_text', '')
        if not text:
            return state

        # æ‰§è¡Œå¤„ç†
        processed = {
            'cleaned': self._clean_text(text),
            'summarized': self._summarize(text),
            'enhanced': self._enhance(text),
            'formatted': self._format(text)
        }

        data['processing'] = processed
        state['metadata']['phase'] = 'processing_complete'
        state['metadata']['progress'] = '75%'

        self.log("å¤„ç†å®Œæˆ: æ¸…ç†, æ‘˜è¦, å¢å¼º, æ ¼å¼åŒ–")

        return state

    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬"""
        # å»é™¤å¤šä½™ç©ºæ ¼
        lines = text.split('\n')
        cleaned = [line.strip() for line in lines if line.strip()]
        return '\n'.join(cleaned)

    def _summarize(self, text: str) -> str:
        """ç”Ÿæˆæ‘˜è¦"""
        sentences = [s.strip() for s in text.split('.') if s.strip()]
        if len(sentences) <= 3:
            return text

        # è¿”å›å‰ä¸¤å¥ä½œä¸ºæ‘˜è¦
        return '. '.join(sentences[:2]) + '.'

    def _enhance(self, text: str) -> str:
        """å¢å¼ºæ–‡æœ¬"""
        # æ·»åŠ å…ƒæ•°æ®
        word_count = len(text.split())
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        header = f"# æ–‡æ¡£å¢å¼ºç‰ˆæœ¬\nç”Ÿæˆæ—¶é—´: {timestamp}\nè¯æ•°: {word_count}\n\n"

        return header + text

    def _format(self, text: str) -> Dict[str, Any]:
        """æ ¼å¼åŒ–ä¿¡æ¯"""
        return {
            'paragraphs': len([p for p in text.split('\n\n') if p.strip()]),
            'sentences': len([s for s in text.split('.') if s.strip()]),
            'words': len(text.split()),
            'characters': len(text)
        }


class ReviewerAgent(BaseAgent):
    """å®¡æŸ¥å¸ˆAgent - è´Ÿè´£è´¨é‡å®¡æŸ¥å’ŒæŠ¥å‘Šç”Ÿæˆ"""

    def __init__(self):
        super().__init__(
            name="reviewer",
            role="è´¨é‡å®¡æŸ¥å¸ˆ",
            expertise=["è´¨é‡è¯„ä¼°", "æŠ¥å‘Šç”Ÿæˆ", "å»ºè®®æä¾›"]
        )

    def process(self, state: State) -> State:
        """å®¡æŸ¥å·¥ä½œç»“æœå¹¶ç”ŸæˆæŠ¥å‘Š"""
        data = state['data']

        # æ”¶é›†æ‰€æœ‰Agentçš„å·¥ä½œç»“æœ
        analysis = data.get('analysis', {})
        processing = data.get('processing', {})

        # ç”Ÿæˆè¯„åˆ†
        scores = self._calculate_scores(analysis, processing)

        # ç”Ÿæˆå»ºè®®
        recommendations = self._generate_recommendations(analysis, processing)

        # åˆ›å»ºæŠ¥å‘Š
        report = {
            'timestamp': datetime.now().isoformat(),
            'input_summary': {
                'original_text': data.get('input_text', '')[:100] + '...',
                'word_count': analysis.get('word_count', 0)
            },
            'analysis_results': analysis,
            'processing_results': {
                'cleaned_preview': processing.get('cleaned', '')[:100] + '...',
                'summary': processing.get('summarized', ''),
                'stats': processing.get('formatted', {})
            },
            'quality_scores': scores,
            'recommendations': recommendations,
            'agent_contributions': {
                'coordinator': 'ä»»åŠ¡è§„åˆ’å’Œåè°ƒ',
                'analyst': 'å†…å®¹åˆ†æå’Œç‰¹å¾æå–',
                'processor': 'æ–‡æœ¬å¤„ç†å’Œä¼˜åŒ–',
                'reviewer': 'è´¨é‡å®¡æŸ¥å’ŒæŠ¥å‘Šç”Ÿæˆ'
            }
        }

        data['report'] = report
        state['metadata']['phase'] = 'review_complete'
        state['metadata']['progress'] = '100%'

        self.log("å®¡æŸ¥å®Œæˆï¼Œå·²ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
        self.log(f"æ€»ä½“è¯„åˆ†: {scores['overall']}/100")

        return state

    def _calculate_scores(self, analysis: Dict, processing: Dict) -> Dict[str, float]:
        """è®¡ç®—è´¨é‡è¯„åˆ†"""
        scores = {}

        # æ–‡æœ¬è´¨é‡åˆ†ï¼ˆåŸºäºåˆ†æç»“æœï¼‰
        complexity_bonus = {
            'ç®€å•': 0.8,
            'ä¸­ç­‰': 1.0,
            'å¤æ‚': 1.2
        }.get(analysis.get('complexity', 'ä¸­ç­‰'), 1.0)

        sentiment_bonus = {
            'ç§¯æ': 1.1,
            'ä¸­æ€§': 1.0,
            'æ¶ˆæ': 0.9
        }.get(analysis.get('sentiment', 'ä¸­æ€§'), 1.0)

        text_quality = 50.0 * complexity_bonus * sentiment_bonus
        scores['text_quality'] = min(100.0, text_quality)

        # å¤„ç†å®Œæ•´æ€§åˆ†
        processing_completeness = 0
        if processing.get('cleaned'):
            processing_completeness += 25
        if processing.get('summarized'):
            processing_completeness += 25
        if processing.get('enhanced'):
            processing_completeness += 25
        if processing.get('formatted'):
            processing_completeness += 25

        scores['processing_completeness'] = processing_completeness

        # åˆ†ææ·±åº¦åˆ†
        analysis_depth = 0
        if analysis.get('keywords'):
            analysis_depth += min(30, len(analysis['keywords']) * 3)
        if analysis.get('sentiment'):
            analysis_depth += 20
        if analysis.get('complexity'):
            analysis_depth += 20
        if analysis.get('word_count'):
            analysis_depth += 30

        scores['analysis_depth'] = min(100.0, analysis_depth)

        # æ€»ä½“è¯„åˆ†
        scores['overall'] = (
            scores['text_quality'] * 0.3 +
            scores['processing_completeness'] * 0.4 +
            scores['analysis_depth'] * 0.3
        )

        return scores

    def _generate_recommendations(self, analysis: Dict, processing: Dict) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []

        # åŸºäºåˆ†æçš„å»ºè®®
        if analysis.get('word_count', 0) < 50:
            recommendations.append("æ–‡æœ¬è¾ƒçŸ­ï¼Œå»ºè®®æ‰©å±•å†…å®¹")
        elif analysis.get('word_count', 0) > 1000:
            recommendations.append("æ–‡æœ¬è¾ƒé•¿ï¼Œå»ºè®®åˆ†æ®µå¤„ç†")

        if analysis.get('complexity') == 'ç®€å•':
            recommendations.append("æ–‡æœ¬ç®€å•ï¼Œé€‚åˆå¿«é€Ÿé˜…è¯»")
        elif analysis.get('complexity') == 'å¤æ‚':
            recommendations.append("æ–‡æœ¬å¤æ‚ï¼Œå»ºè®®å¢åŠ è§£é‡Šè¯´æ˜")

        # åŸºäºæƒ…æ„Ÿçš„å»ºè®®
        if analysis.get('sentiment') == 'æ¶ˆæ':
            recommendations.append("æ£€æµ‹åˆ°æ¶ˆææƒ…æ„Ÿï¼Œå»ºè®®è°ƒæ•´è¯­æ°”")

        return recommendations if recommendations else ["æ–‡æ¡£è´¨é‡è‰¯å¥½ï¼Œæ— éœ€ç‰¹åˆ«æ”¹è¿›"]


# ============================================================================
# å¤šAgentç³»ç»Ÿç¼–æ’å™¨
# ============================================================================

class MultiAgentSystem:
    """å¤šAgentç³»ç»Ÿ - åè°ƒå¤šä¸ªAgentåä½œ"""

    def __init__(self):
        self.agents = {
            'coordinator': CoordinatorAgent(),
            'analyst': AnalystAgent(),
            'processor': ProcessorAgent(),
            'reviewer': ReviewerAgent()
        }
        self.workflow = None

    def build_workflow(self) -> WorkflowGraph:
        """æ„å»ºå¤šAgentå·¥ä½œæµ"""
        graph = WorkflowGraph("document_processing_team")

        # æ·»åŠ æ‰€æœ‰AgentèŠ‚ç‚¹
        for agent_name, agent in self.agents.items():
            graph.add_node(agent_name, agent)

        # å®šä¹‰å·¥ä½œæµç¨‹ï¼šä¸²è¡Œåä½œ
        # åè°ƒè€… â†’ åˆ†æå¸ˆ â†’ å¤„ç†å™¨ â†’ å®¡æŸ¥å¸ˆ â†’ ç»“æŸ
        graph.add_edge("coordinator", "analyst")
        graph.add_edge("analyst", "processor")
        graph.add_edge("processor", "reviewer")
        graph.add_edge("reviewer", END)

        # è®¾ç½®å…¥å£ç‚¹
        graph.set_entry_point("coordinator")

        return graph.compile()

    def process(self, input_text: str) -> Dict[str, Any]:
        """å¤„ç†è¾“å…¥æ–‡æœ¬"""
        print("=" * 70)
        print("ğŸ¤– å¤šAgentæ–‡æ¡£å¤„ç†å›¢é˜Ÿå¯åŠ¨")
        print("=" * 70)
        print()

        # æ„å»ºå·¥ä½œæµ
        if not self.workflow:
            self.workflow = self.build_workflow()

        # å‡†å¤‡åˆå§‹æ•°æ®ï¼ˆä¼šè‡ªåŠ¨åŒ…è£…æˆStateï¼‰
        initial_data = {
            'input_text': input_text,
            'phase': 'initializing',
            'progress': '0%'
        }

        # æ‰§è¡Œå·¥ä½œæµ
        result = self.workflow.invoke(initial_data)

        # æ‰“å°ç»“æœæ‘˜è¦
        self._print_summary(result)

        return result

    def _print_summary(self, result: Dict[str, Any]):
        """æ‰“å°å¤„ç†æ‘˜è¦"""
        print()
        print("=" * 70)
        print("ğŸ“Š å¤„ç†å®Œæˆæ‘˜è¦")
        print("=" * 70)

        # resultå°±æ˜¯dataéƒ¨åˆ†
        data = result
        report = data.get('report', {})
        analysis = data.get('analysis', {})

        if report:
            print(f"\nâ° å¤„ç†æ—¶é—´: {report.get('timestamp', 'N/A')}")

            if 'input_summary' in report:
                print(f"ğŸ“ è¯æ•°ç»Ÿè®¡: {report['input_summary'].get('word_count', 0)} è¯")

            if analysis:
                print(f"\nğŸ” åˆ†æç»“æœ:")
                print(f"   - è¯æ•°: {analysis.get('word_count', 0)}")
                print(f"   - è¡Œæ•°: {analysis.get('line_count', 0)}")
                print(f"   - æƒ…æ„Ÿ: {analysis.get('sentiment', 'N/A')}")
                print(f"   - å¤æ‚åº¦: {analysis.get('complexity', 'N/A')}")
                keywords = analysis.get('keywords', [])[:3]
                print(f"   - å…³é”®è¯: {', '.join(keywords)}")

            if 'quality_scores' in report:
                scores = report['quality_scores']
                print(f"\nğŸ“ˆ è´¨é‡è¯„åˆ†:")
                print(f"   - æ–‡æœ¬è´¨é‡: {scores['text_quality']:.1f}/100")
                print(f"   - å¤„ç†å®Œæ•´åº¦: {scores['processing_completeness']:.1f}/100")
                print(f"   - åˆ†ææ·±åº¦: {scores['analysis_depth']:.1f}/100")
                print(f"   - ç»¼åˆè¯„åˆ†: {scores['overall']:.1f}/100")

            if 'recommendations' in report:
                print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
                for i, rec in enumerate(report['recommendations'], 1):
                    print(f"   {i}. {rec}")

        print("\n" + "=" * 70)


# ============================================================================
# ä¸»ç¨‹åº
# ============================================================================

def main():
    """ä¸»ç¨‹åº - æ¼”ç¤ºå¤šAgentç³»ç»Ÿ"""

    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                    â•‘
â•‘             å¤šAgentç³»ç»ŸåŸå‹ - æ™ºèƒ½æ–‡æ¡£å¤„ç†å›¢é˜Ÿ                       â•‘
â•‘                                                                    â•‘
â•‘  Agentå›¢é˜Ÿæˆå‘˜:                                                    â•‘
â•‘    ğŸ¯ åè°ƒè€… (Coordinator) - ä»»åŠ¡è§„åˆ’å’Œèµ„æºåˆ†é…                      â•‘
â•‘    ğŸ” åˆ†æå¸ˆ (Analyst) - å†…å®¹åˆ†æå’Œç‰¹å¾æå–                          â•‘
â•‘    âš™ï¸ å¤„ç†å™¨ (Processor) - æ–‡æœ¬å¤„ç†å’Œä¼˜åŒ–                           â•‘
â•‘    âœ… å®¡æŸ¥å¸ˆ (Reviewer) - è´¨é‡å®¡æŸ¥å’ŒæŠ¥å‘Šç”Ÿæˆ                         â•‘
â•‘                                                                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    # åˆ›å»ºå¤šAgentç³»ç»Ÿ
    mas = MultiAgentSystem()

    # ç¤ºä¾‹1: ç®€å•æ–‡æœ¬
    print("\nğŸ”µ ç¤ºä¾‹1: ç®€å•æ–‡æœ¬å¤„ç†")
    print("-" * 70)
    sample1 = """
    å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸€ä¸ªçƒ­é—¨ç ”ç©¶æ–¹å‘ã€‚
    é€šè¿‡è®©å¤šä¸ªä¸“é—¨çš„Agentåä½œï¼Œå¯ä»¥å®Œæˆæ¯”å•ä¸ªAgentæ›´å¤æ‚çš„ä»»åŠ¡ã€‚
    æ¯ä¸ªAgentéƒ½æœ‰è‡ªå·±çš„ä¸“é•¿å’ŒèŒè´£ï¼Œå®ƒä»¬é€šè¿‡åè°ƒå’Œé€šä¿¡æ¥å®ç°å…±åŒçš„ç›®æ ‡ã€‚
    è¿™ç§æ–¹å¼æ¨¡æ‹Ÿäº†äººç±»ç¤¾ä¼šä¸­çš„å›¢é˜Ÿåˆä½œæ¨¡å¼ã€‚
    """

    mas.process(sample1.strip())

    # ç¤ºä¾‹2: å¤æ‚æ–‡æœ¬
    print("\n\nğŸŸ¢ ç¤ºä¾‹2: å¤æ‚æ–‡æ¡£åˆ†æ")
    print("-" * 70)
    sample2 = """
    # äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•å†ç¨‹

    äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligenceï¼Œç®€ç§°AIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œ
    å®ƒè‡´åŠ›äºç ”ç©¶ã€å¼€å‘ç”¨äºæ¨¡æ‹Ÿã€å»¶ä¼¸å’Œæ‰©å±•äººçš„æ™ºèƒ½çš„ç†è®ºã€æ–¹æ³•ã€æŠ€æœ¯åŠåº”ç”¨ç³»ç»Ÿã€‚

    ## å‘å±•é˜¶æ®µ

    äººå·¥æ™ºèƒ½çš„å‘å±•å¯ä»¥åˆ†ä¸ºå‡ ä¸ªé‡è¦é˜¶æ®µï¼š
    1. è¯ç”ŸæœŸï¼ˆ1950-1970å¹´ä»£ï¼‰ï¼šå›¾çµæµ‹è¯•çš„æå‡ºï¼Œä¸“å®¶ç³»ç»Ÿçš„å‡ºç°
    2. å‘å±•æœŸï¼ˆ1980-1990å¹´ä»£ï¼‰ï¼šæœºå™¨å­¦ä¹ ç®—æ³•çš„çªç ´
    3. çˆ†å‘æœŸï¼ˆ2000å¹´ä»£è‡³ä»Šï¼‰ï¼šæ·±åº¦å­¦ä¹ ã€å¤§è¯­è¨€æ¨¡å‹çš„å¿«é€Ÿå‘å±•

    ## åº”ç”¨é¢†åŸŸ

    äººå·¥æ™ºèƒ½å·²ç»å¹¿æ³›åº”ç”¨äºï¼š
    - è‡ªç„¶è¯­è¨€å¤„ç†
    - è®¡ç®—æœºè§†è§‰
    - æ™ºèƒ½æ¨èç³»ç»Ÿ
    - è‡ªåŠ¨é©¾é©¶
    - åŒ»ç–—è¯Šæ–­

    æœªæ¥ï¼Œäººå·¥æ™ºèƒ½å°†ç»§ç»­æ·±åˆ»æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»å’Œå·¥ä½œæ–¹å¼ã€‚
    è¿™æ˜¯ä¸€ä¸ªexcellentçš„å‘å±•æ–¹å‘ï¼Œæˆ‘ä»¬éƒ½åº”è¯¥å…³æ³¨å’Œæ‹¥æŠ±è¿™ä¸ªè¶‹åŠ¿ã€‚
    """

    mas.process(sample2.strip())

    print("\n\nâœ… å¤šAgentç³»ç»Ÿæ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸ’¡ æç¤º:")
    print("   - è¿™ä¸ªç³»ç»Ÿå±•ç¤ºäº†4ä¸ªAgentå¦‚ä½•åä½œå®Œæˆä»»åŠ¡")
    print("   - æ¯ä¸ªAgentä¸“æ³¨äºè‡ªå·±çš„èŒè´£èŒƒå›´")
    print("   - é€šè¿‡WorkflowGraphå®ç°å·¥ä½œæµç¼–æ’")
    print("   - çŠ¶æ€åœ¨Agentä¹‹é—´ä¼ é€’å’Œæ›´æ–°")
    print("   - å¯ä»¥æ‰©å±•æ›´å¤šAgentæˆ–æ”¹å˜å·¥ä½œæµç¨‹")


if __name__ == "__main__":
    main()
