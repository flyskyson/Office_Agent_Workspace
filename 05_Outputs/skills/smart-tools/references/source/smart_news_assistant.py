# -*- coding: utf-8 -*-
"""
æ™ºèƒ½æ–°é—»åŠ©æ‰‹ v2.0
Smart News Assistant

åŠŸèƒ½:
1. ä»å¤šä¸ªå¹³å°è·å–çœŸå®æ–°é—»ï¼ˆæ”¯æŒ MCP æœåŠ¡å™¨ï¼‰
2. åŸºäºç”¨æˆ·å…´è¶£å…³é”®è¯è¿›è¡Œæ™ºèƒ½åŒ¹é…
3. è‡ªåŠ¨ä¿å­˜æ¨èå†å²

ä½œè€…: Office Agent Workspace
ç‰ˆæœ¬: 2.0.0
æ›´æ–°: 2026-01-16 - é›†æˆ MCP æ–°é—»å®¢æˆ·ç«¯
"""

import asyncio
import json
import sys
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Set, Tuple
import subprocess
import re

# Windows ç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')

# æ·»åŠ  Agent Library åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "00_Agent_Library"))


class InterestMatcher:
    """å…´è¶£åŒ¹é…å™¨"""

    def __init__(self, interests_path: Path = None):
        if interests_path is None:
            interests_path = Path(__file__).parent.parent / "06_Learning_Journal" / "workspace_memory" / "user_interests.json"

        self.interests_path = interests_path
        self.long_term: Set[str] = set()
        self.short_term: Set[str] = set()
        self.implicit: Set[str] = set()

        self._load_interests()

    def _load_interests(self):
        """åŠ è½½å…´è¶£å…³é”®è¯"""
        if self.interests_path.exists():
            try:
                data = json.loads(self.interests_path.read_text(encoding="utf-8"))
                self.long_term = set(data.get("long_term", []))
                self.short_term = set(data.get("short_term", []))
                self.implicit = set(data.get("implicit", []))
                print(f"âœ… å·²åŠ è½½ {len(self.long_term)} ä¸ªé•¿æœŸå…´è¶£ï¼Œ{len(self.short_term)} ä¸ªçŸ­æœŸå…³æ³¨")
            except Exception as e:
                print(f"âš ï¸  åŠ è½½å…´è¶£å¤±è´¥: {e}")

    def calculate_match_score(self, title: str) -> Tuple[float, List[str]]:
        """è®¡ç®—åŒ¹é…åº¦åˆ†æ•°

        Returns:
            (åˆ†æ•°, åŒ¹é…çš„å…³é”®è¯åˆ—è¡¨)
        """
        title_lower = title.lower()
        matched_keywords = []
        score = 0.0

        # çŸ­æœŸå…³æ³¨æƒé‡æœ€é«˜ (3.0)
        for keyword in self.short_term:
            if keyword.lower() in title_lower:
                score += 3.0
                matched_keywords.append(f"[çŸ­]{keyword}")

        # é•¿æœŸå…´è¶£æ¬¡ä¹‹ (1.0)
        for keyword in self.long_term:
            if keyword.lower() in title_lower:
                score += 1.0
                matched_keywords.append(f"[é•¿]{keyword}")

        # éšå¼å­¦ä¹ çš„å…³é”®è¯ (0.5)
        for keyword in self.implicit:
            if keyword.lower() in title_lower:
                score += 0.5
                matched_keywords.append(f"[éš]{keyword}")

        return min(score, 100.0), matched_keywords


class SmartNewsAssistant:
    """æ™ºèƒ½æ–°é—»åŠ©æ‰‹ v2.0 - é›†æˆ MCP å®¢æˆ·ç«¯"""

    def __init__(self, use_mcp: bool = True):
        """
        åˆå§‹åŒ–åŠ©æ‰‹

        Args:
            use_mcp: æ˜¯å¦ä½¿ç”¨ MCP å®¢æˆ·ç«¯ï¼ˆé»˜è®¤ Trueï¼‰
        """
        self.matcher = InterestMatcher()
        self.storage_path = Path(__file__).parent.parent / "06_Learning_Journal" / "workspace_memory"
        self.storage_path.mkdir(parents=True, exist_ok=True)
        self.history_file = self.storage_path / "news_recommendations.jsonl"
        self.use_mcp = use_mcp

        # å»¶è¿Ÿå¯¼å…¥ MCP å®¢æˆ·ç«¯
        if use_mcp:
            try:
                from mcp_news_client import MCPNewsClient
                self.mcp_client = MCPNewsClient()
                print("âœ… MCP å®¢æˆ·ç«¯å·²åŠ è½½")
            except ImportError:
                print("âš ï¸  MCP å®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
                self.use_mcp = False
                self.mcp_client = None

    async def fetch_from_mcp(self, platforms: List[str] = None, limit: int = 20) -> List[Dict]:
        """
        ä½¿ç”¨ MCP å®¢æˆ·ç«¯è·å–æ–°é—»

        Args:
            platforms: å¹³å°åˆ—è¡¨ï¼ˆå¦‚ ["zhihu", "weibo", "github"]ï¼‰
            limit: æ¯ä¸ªå¹³å°è·å–æ•°é‡

        Returns:
            æ‰€æœ‰å¹³å°çš„æ–°é—»åˆ—è¡¨
        """
        if not self.use_mcp or not self.mcp_client:
            return []

        if platforms is None:
            # æŠ€æœ¯å¹³å°é»˜è®¤
            platforms = ["zhihu", "github", "csdn", "36kr"]

        try:
            results = await self.mcp_client.get_news(platforms, limit)

            # åˆå¹¶æ‰€æœ‰å¹³å°çš„æ–°é—»
            all_news = []
            for platform, data in results.get("platforms", {}).items():
                for item in data.get("news_list", []):
                    item["source_platform"] = platform
                    all_news.append(item)

            return all_news

        except Exception as e:
            print(f"âš ï¸  MCP è·å–å¤±è´¥: {e}")
            return []

    async def fetch_from_scraper(self, platform: str = "weibo", limit: int = 20) -> List[Dict]:
        """
        ä½¿ç”¨ Playwright çˆ¬è™«è·å–æ–°é—»ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰

        Args:
            platform: æ–°é—»å¹³å°
            limit: è·å–æ•°é‡
        """
        scraper_path = Path(__file__).parent / "news_scraper.py"

        if not scraper_path.exists():
            print(f"âš ï¸  çˆ¬è™«æ–‡ä»¶ä¸å­˜åœ¨: {scraper_path}")
            return []

        try:
            # è°ƒç”¨çˆ¬è™«è„šæœ¬
            result = subprocess.run(
                [sys.executable, str(scraper_path), "-p", platform, "-n", str(limit)],
                capture_output=True,
                text=True,
                encoding='utf-8',
                timeout=60
            )

            if result.returncode == 0:
                # è§£æè¾“å‡ºï¼ˆç®€åŒ–å¤„ç†ï¼‰
                news_items = []
                lines = result.stdout.split('\n')

                current_item = {}
                for line in lines:
                    # è§£ææ ¼å¼: "1. æ ‡é¢˜"
                    match = re.match(r'^\s*(\d+)\.\s+(.+)', line)
                    if match:
                        if current_item:
                            news_items.append(current_item)
                        current_item = {"title": match.group(2), "rank": int(match.group(1))}

                    # è§£æçƒ­åº¦
                    hot_match = re.search(r'ğŸ”¥\s*çƒ­åº¦:\s*([\d,]+)', line)
                    if hot_match and current_item:
                        current_item["hot"] = hot_match.group(1)

                    # è§£æé“¾æ¥
                    url_match = re.search(r'ğŸ”—\s*(https?://\S+)', line)
                    if url_match and current_item:
                        current_item["url"] = url_match.group(1)

                if current_item:
                    news_items.append(current_item)

                return news_items
        except Exception as e:
            print(f"âš ï¸  çˆ¬è™«è·å–å¤±è´¥: {e}")

        return []

    def match_news(self, news_list: List[Dict], threshold: float = 1.0) -> List[Dict]:
        """åŒ¹é…ç”¨æˆ·æ„Ÿå…´è¶£çš„æ–°é—»

        Args:
            news_list: æ–°é—»åˆ—è¡¨
            threshold: æœ€ä½åŒ¹é…åˆ†æ•°é˜ˆå€¼

        Returns:
            åŒ…å«åŒ¹é…åº¦åˆ†æ•°çš„æ–°é—»åˆ—è¡¨
        """
        matched = []

        for news in news_list:
            title = news.get('title', '')
            score, keywords = self.matcher.calculate_match_score(title)

            if score >= threshold:
                news_with_score = news.copy()
                news_with_score['match_score'] = round(score, 1)
                news_with_score['matched_keywords'] = keywords
                matched.append(news_with_score)

        # æŒ‰åŒ¹é…åº¦æ’åº
        matched.sort(key=lambda x: x['match_score'], reverse=True)
        return matched

    def format_recommendations(self, news_list: List[Dict]) -> str:
        """æ ¼å¼åŒ–æ¨èè¾“å‡º"""
        lines = []
        lines.append("=" * 70)
        lines.append("ğŸ“° æ™ºèƒ½æ–°é—»æ¨è")
        lines.append("=" * 70)
        lines.append(f"â° æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"ğŸ“Š æ‰¾åˆ° {len(news_list)} æ¡æ‚¨å¯èƒ½æ„Ÿå…´è¶£çš„æ–°é—»")
        lines.append("")

        if not news_list:
            lines.append("ğŸ˜” æš‚æ— åŒ¹é…çš„æ–°é—»")
            lines.append("")
            lines.append("ğŸ’¡ å»ºè®®:")
            lines.append("   - å½“å‰çƒ­æœå¯èƒ½ä¸æ‚¨çš„å…´è¶£é¢†åŸŸä¸åŒ¹é…")
            lines.append("   - å¯ä»¥å°è¯•æ·»åŠ æ›´å¤šå…´è¶£å…³é”®è¯")
            lines.append("   - æˆ–è€…æŸ¥çœ‹æŠ€æœ¯ç±»å¹³å°ï¼ˆçŸ¥ä¹ã€GitHubï¼‰")
            return "\n".join(lines)

        # æŒ‰åŒ¹é…åº¦åˆ†ç»„
        high_match = [n for n in news_list if n['match_score'] >= 3.0]
        medium_match = [n for n in news_list if 1.0 <= n['match_score'] < 3.0]

        if high_match:
            lines.append("ğŸ”¥ é«˜åº¦åŒ¹é…æ¨è")
            lines.append("-" * 70)
            for i, news in enumerate(high_match[:5], 1):
                lines.append(f"{i}. {news.get('title', 'N/A')}")
                lines.append(f"   ğŸ¯ åŒ¹é…åº¦: {news['match_score']}%")
                if news.get('matched_keywords'):
                    lines.append(f"   ğŸ”‘ å…³é”®è¯: {', '.join(news['matched_keywords'][:3])}")
                if news.get('hot'):
                    lines.append(f"   ğŸ”¥ çƒ­åº¦: {news['hot']}")
                if news.get('url'):
                    lines.append(f"   ğŸ”— {news['url']}")
                lines.append("")

        if medium_match and len(medium_match) > len(high_match):
            lines.append("ğŸ’¡ å¯èƒ½æ„Ÿå…´è¶£")
            lines.append("-" * 70)
            for i, news in enumerate(medium_match[:5], 1):
                lines.append(f"{i}. {news.get('title', 'N/A')}")
                lines.append(f"   ğŸ¯ åŒ¹é…åº¦: {news['match_score']}%")
                if news.get('url'):
                    lines.append(f"   ğŸ”— {news['url']}")
                lines.append("")

        return "\n".join(lines)

    def save_recommendation(self, news_list: List[Dict]):
        """ä¿å­˜æ¨èå†å²"""
        try:
            record = {
                "timestamp": datetime.now().isoformat(),
                "count": len(news_list),
                "news": news_list[:10]  # åªä¿å­˜å‰10æ¡
            }

            with open(self.history_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(record, ensure_ascii=False) + '\n')
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜å†å²å¤±è´¥: {e}")

    async def run(self, platforms: List[str] = None, limit: int = 20, mode: str = "auto"):
        """
        è¿è¡Œæ™ºèƒ½æ¨è

        Args:
            platforms: å¹³å°åˆ—è¡¨ï¼ˆå¤šå¹³å°æ¨¡å¼ï¼‰æˆ–å•ä¸ªå¹³å°åç§°ï¼ˆå…¼å®¹æ—§ç‰ˆï¼‰
            limit: è·å–æ•°é‡
            mode: è¿è¡Œæ¨¡å¼
                - "auto": è‡ªåŠ¨é€‰æ‹©ï¼ˆä¼˜å…ˆ MCPï¼Œé™çº§åˆ°çˆ¬è™«ï¼‰
                - "mcp": å¼ºåˆ¶ä½¿ç”¨ MCP
                - "scraper": å¼ºåˆ¶ä½¿ç”¨çˆ¬è™«
        """
        print("=" * 70)
        print("ğŸ¤– æ™ºèƒ½æ–°é—»åŠ©æ‰‹ v2.0")
        print("=" * 70)

        # å…¼å®¹æ—§ç‰ˆå•å¹³å°æ¨¡å¼
        if isinstance(platforms, str):
            platforms = [platforms]

        if platforms is None:
            platforms = ["zhihu", "github", "csdn"]

        print(f"ğŸ“ å¹³å°: {', '.join(platforms)}")
        print(f"ğŸ“Š æ•°é‡: {limit}")
        print(f"ğŸ”§ æ¨¡å¼: {mode} (MCP: {'å¯ç”¨' if self.use_mcp else 'ç¦ç”¨'})")
        print("")

        # 1. è·å–æ–°é—»
        news_list = []

        if mode == "scraper" or not self.use_mcp:
            # çˆ¬è™«æ¨¡å¼
            for platform in platforms:
                print(f"ğŸ“¡ æ­£åœ¨è·å– {platform} çƒ­ç‚¹...")
                items = await self.fetch_from_scraper(platform, limit)
                news_list.extend(items)
        else:
            # MCP æ¨¡å¼
            print(f"ğŸ“¡ æ­£åœ¨ä» MCP è·å–æ–°é—»...")
            news_list = await self.fetch_from_mcp(platforms, limit)

        if not news_list:
            print("âŒ è·å–æ–°é—»å¤±è´¥")
            return

        print(f"âœ… è·å–åˆ° {len(news_list)} æ¡æ–°é—»")
        print("")

        # 2. åŒ¹é…å…´è¶£
        print("ğŸ§  æ­£åœ¨åˆ†ææ‚¨çš„å…´è¶£...")
        matched_news = self.match_news(news_list)
        print("")

        # 3. æ˜¾ç¤ºæ¨è
        print(self.format_recommendations(matched_news))

        # 4. ä¿å­˜å†å²
        self.save_recommendation(matched_news)

        return matched_news


async def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import argparse

    parser = argparse.ArgumentParser(
        description="æ™ºèƒ½æ–°é—»åŠ©æ‰‹ v2.0 - é›†æˆ MCP å®¢æˆ·ç«¯",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # ä½¿ç”¨ MCP è·å–å¤šå¹³å°æ–°é—»ï¼ˆæ¨èï¼‰
  python smart_news_assistant.py -p zhihu github csdn

  # ä½¿ç”¨çˆ¬è™«æ¨¡å¼
  python smart_news_assistant.py -p weibo -m scraper

  # è·å–æŠ€æœ¯æ–°é—»
  python smart_news_assistant.py -p zhihu github 36kr -n 30
        """
    )

    parser.add_argument(
        "-p", "--platforms",
        nargs="+",
        default=["zhihu", "github", "csdn"],
        help="æ–°é—»å¹³å°åˆ—è¡¨ï¼ˆé»˜è®¤: zhihu github csdnï¼‰"
    )
    parser.add_argument(
        "-n", "--num",
        type=int,
        default=20,
        help="æ¯ä¸ªå¹³å°è·å–æ•°é‡ (é»˜è®¤: 20)"
    )
    parser.add_argument(
        "-m", "--mode",
        choices=["auto", "mcp", "scraper"],
        default="auto",
        help="è¿è¡Œæ¨¡å¼ (é»˜è®¤: auto)"
    )

    args = parser.parse_args()

    assistant = SmartNewsAssistant(use_mcp=(args.mode != "scraper"))
    await assistant.run(args.platforms, args.num, args.mode)


if __name__ == "__main__":
    asyncio.run(main())
