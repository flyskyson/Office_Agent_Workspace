# -*- coding: utf-8 -*-
"""
æ™ºèƒ½æ–°é—»ç›‘æ§åŠ©æ‰‹
Smart News Monitor Assistant

åŠŸèƒ½:
1. è®°ä½ç”¨æˆ·çš„å…´è¶£ç‚¹ (é•¿æœŸå’ŒçŸ­æœŸ)
2. ä»å¤šå¹³å°è·å–çƒ­ç‚¹æ–°é—»
3. æ™ºèƒ½åŒ¹é…ç›¸å…³æ–°é—»
4. ä¸»åŠ¨æ¨é€ç”¨æˆ·æ„Ÿå…´è¶£çš„å†…å®¹

ä½œè€…: Office Agent Workspace
ç‰ˆæœ¬: 1.0.0
"""

import asyncio
import json
import sys
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Set
import re

# Windows ç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')


class InterestMemory:
    """å…´è¶£è®°å¿†ç³»ç»Ÿ"""

    def __init__(self, storage_path: Path = None):
        if storage_path is None:
            storage_path = Path(__file__).parent.parent / "06_Learning_Journal" / "workspace_memory"
        self.storage_path = storage_path
        self.interest_file = storage_path / "user_interests.json"

        # å…´è¶£åˆ†ç±»
        self.long_term_interests: Set[str] = set()  # é•¿æœŸå…´è¶£
        self.short_term_interests: Set[str] = set()  # çŸ­æœŸå…³æ³¨
        self.implicit_keywords: Set[str] = set()  # éšå¼å­¦ä¹ çš„å…³é”®è¯

        # æ—¶é—´æˆ³
        self.last_update = None

        self._load()

    def _load(self):
        """åŠ è½½å…´è¶£æ•°æ®"""
        if self.interest_file.exists():
            try:
                data = json.loads(self.interest_file.read_text(encoding="utf-8"))
                self.long_term_interests = set(data.get("long_term", []))
                self.short_term_interests = set(data.get("short_term", []))
                self.implicit_keywords = set(data.get("implicit", []))
                self.last_update = data.get("last_update")
                print(f"âœ… å·²åŠ è½½ {len(self.long_term_interests)} ä¸ªé•¿æœŸå…´è¶£ï¼Œ{len(self.short_term_interests)} ä¸ªçŸ­æœŸå…³æ³¨")
            except Exception as e:
                print(f"âš ï¸  åŠ è½½å…´è¶£æ•°æ®å¤±è´¥: {e}")
                self._init_default_interests()
        else:
            self._init_default_interests()

    def _init_default_interests(self):
        """åˆå§‹åŒ–é»˜è®¤å…´è¶£"""
        # åŸºäºå·¥ä½œåŒºçš„é»˜è®¤å…´è¶£
        self.long_term_interests = {
            "AI", "äººå·¥æ™ºèƒ½", "Python", "åŠå…¬è‡ªåŠ¨åŒ–",
            "Flask", "Streamlit", "OCR", "å¸‚åœºç›‘ç®¡",
            "çŸ¥è¯†ç®¡ç†", "å‘é‡åŒ–", "MCP", "Claude"
        }
        self.short_term_interests = set()
        self.implicit_keywords = set()
        self.save()

    def save(self):
        """ä¿å­˜å…´è¶£æ•°æ®"""
        self.storage_path.mkdir(parents=True, exist_ok=True)
        data = {
            "long_term": list(self.long_term_interests),
            "short_term": list(self.short_term_interests),
            "implicit": list(self.implicit_keywords),
            "last_update": datetime.now().isoformat()
        }
        self.interest_file.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")

    def add_long_term(self, keyword: str):
        """æ·»åŠ é•¿æœŸå…´è¶£"""
        self.long_term_interests.add(keyword)
        self.save()

    def add_short_term(self, keyword: str, days=7):
        """æ·»åŠ çŸ­æœŸå…³æ³¨ (è‡ªåŠ¨è¿‡æœŸ)"""
        self.short_term_interests.add(keyword)
        self.save()

    def learn_implicit(self, text: str):
        """ä»æ–‡æœ¬ä¸­éšå¼å­¦ä¹ å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–
        keywords = re.findall(r'[\u4e00-\u9fa5a-zA-Z]{2,}', text)
        for keyword in keywords:
            if len(keyword) >= 2 and keyword not in self.long_term_interests:
                self.implicit_keywords.add(keyword)
        self.save()

    def get_all_keywords(self) -> Set[str]:
        """è·å–æ‰€æœ‰æœ‰æ•ˆå…³é”®è¯"""
        # æ¸…ç†è¿‡æœŸçš„çŸ­æœŸå…´è¶£
        all_keywords = self.long_term_interests | self.short_term_interests | self.implicit_keywords
        return all_keywords

    def match_score(self, text: str) -> float:
        """è®¡ç®—æ–‡æœ¬ä¸å…´è¶£çš„åŒ¹é…åˆ†æ•°"""
        keywords = self.get_all_keywords()
        if not keywords:
            return 0.0

        text_lower = text.lower()
        matches = sum(1 for kw in keywords if kw.lower() in text_lower)
        return min(matches / len(keywords) * 10, 1.0)  # å½’ä¸€åŒ–åˆ° 0-1


class NewsItem:
    """æ–°é—»æ¡ç›®"""

    def __init__(self, title: str, url: str, platform: str, hot_value: str = "", rank: int = 0):
        self.title = title
        self.url = url
        self.platform = platform
        self.hot_value = hot_value
        self.rank = rank
        self.timestamp = datetime.now()

    def to_dict(self):
        return {
            "title": self.title,
            "url": self.url,
            "platform": self.platform,
            "hot_value": self.hot_value,
            "rank": self.rank,
            "timestamp": self.timestamp.isoformat()
        }


class SmartNewsMonitor:
    """æ™ºèƒ½æ–°é—»ç›‘æ§åŠ©æ‰‹"""

    def __init__(self):
        self.memory = InterestMemory()
        self.last_check = None
        self.cache_file = Path(__file__).parent.parent / "06_Learning_Journal" / "workspace_memory" / "news_cache.json"
        self.cache = self._load_cache()

    def _load_cache(self) -> Dict:
        """åŠ è½½æ–°é—»ç¼“å­˜"""
        if self.cache_file.exists():
            try:
                return json.loads(self.cache_file.read_text(encoding="utf-8"))
            except:
                return {}
        return {}

    def _save_cache(self):
        """ä¿å­˜æ–°é—»ç¼“å­˜"""
        self.cache_file.parent.mkdir(parents=True, exist_ok=True)
        self.cache_file.write_text(json.dumps(self.cache, ensure_ascii=False, indent=2), encoding="utf-8")

    def add_interest(self, keyword: str, interest_type: str = "long"):
        """æ·»åŠ å…´è¶£å…³é”®è¯"""
        if interest_type == "long":
            self.memory.add_long_term(keyword)
            print(f"âœ… å·²æ·»åŠ é•¿æœŸå…´è¶£: {keyword}")
        else:
            self.memory.add_short_term(keyword)
            print(f"âœ… å·²æ·»åŠ çŸ­æœŸå…³æ³¨: {keyword}")

    def learn_from_context(self, text: str):
        """ä»ä¸Šä¸‹æ–‡å­¦ä¹ """
        self.memory.learn_implicit(text)
        print(f"ğŸ§  å·²ä»ä¸Šä¸‹æ–‡å­¦ä¹ å…³é”®è¯")

    async def fetch_hot_news(self) -> List[NewsItem]:
        """è·å–çƒ­ç‚¹æ–°é—»"""
        try:
            from mcp_hot_news.client import HotNewsClient

            all_news = []
            platforms = ["zhihu", "bilibili", "douyin", "kuaishou"]

            async with HotNewsClient() as client:
                tasks = [client.get_hot_news(platform, limit=20) for platform in platforms]
                results = await asyncio.gather(*tasks, return_exceptions=True)

                for platform, result in zip(platforms, results):
                    if isinstance(result, Exception):
                        print(f"âš ï¸  {platform} è·å–å¤±è´¥: {result}")
                        continue

                    for item in result.get("news_list", []):
                        news = NewsItem(
                            title=item.get("title", ""),
                            url=item.get("url", ""),
                            platform=platform,
                            hot_value=str(item.get("hot_value", "")),
                            rank=item.get("rank", 0)
                        )
                        all_news.append(news)

            return all_news

        except ImportError:
            print("âš ï¸  mcp-hot-news æœªå®‰è£…ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            return self._get_mock_news()

    def _get_mock_news(self) -> List[NewsItem]:
        """è·å–æ¨¡æ‹Ÿæ–°é—»æ•°æ®"""
        mock_data = [
            NewsItem("GPT-5 å‘å¸ƒé¢„å‘Šï¼Œæ€§èƒ½æå‡300%", "https://example.com/gpt5", "çŸ¥ä¹", "100ä¸‡çƒ­", 1),
            NewsItem("Python 3.14 æ­£å¼å‘å¸ƒ", "https://example.com/py314", "çŸ¥ä¹", "50ä¸‡çƒ­", 2),
            NewsItem("Flask 4.0 å¸¦æ¥é‡å¤§æ›´æ–°", "https://example.com/flask4", "å“”å“©å“”å“©", "30ä¸‡çƒ­", 1),
            NewsItem("OCR æŠ€æœ¯çªç ´ï¼šè¯†åˆ«å‡†ç¡®ç‡è¾¾99.9%", "https://example.com/ocr", "çŸ¥ä¹", "20ä¸‡çƒ­", 3),
            NewsItem("å¸‚åœºç›‘ç®¡å¼•å…¥ AI æ™ºèƒ½å®¡æ‰¹", "https://example.com/market", "çŸ¥ä¹", "15ä¸‡çƒ­", 4),
        ]
        return mock_data

    def filter_interesting_news(self, news_list: List[NewsItem], threshold: float = 0.3) -> List[NewsItem]:
        """ç­›é€‰æ„Ÿå…´è¶£çš„æ–°é—»"""
        interesting = []
        for news in news_list:
            score = self.memory.match_score(news.title)
            if score >= threshold:
                interesting.append((news, score))
        # æŒ‰åˆ†æ•°æ’åº
        interesting.sort(key=lambda x: x[1], reverse=True)
        return [news for news, _ in interesting]

    async def check_and_notify(self, silent: bool = False) -> List[NewsItem]:
        """æ£€æŸ¥å¹¶é€šçŸ¥æ„Ÿå…´è¶£çš„æ–°é—»"""
        # è·å–æœ€æ–°æ–°é—»
        all_news = await self.fetch_hot_news()

        # ç­›é€‰æ„Ÿå…´è¶£çš„æ–°é—»
        interesting_news = self.filter_interesting_news(all_news)

        if not silent:
            if interesting_news:
                print(f"\nğŸ“° å‘ç° {len(interesting_news)} æ¡æ‚¨å¯èƒ½æ„Ÿå…´è¶£çš„æ–°é—»:")
                print("=" * 60)
                for i, news in enumerate(interesting_news[:10], 1):
                    score = self.memory.match_score(news.title)
                    print(f"\n{i}. [{news.platform}] {news.title}")
                    print(f"   ğŸ”¥ çƒ­åº¦: {news.hot_value} | ğŸ¯ åŒ¹é…åº¦: {score:.1%}")
                    print(f"   ğŸ”— {news.url}")
            else:
                print("ğŸ“­ æš‚æ— æ‚¨æ„Ÿå…´è¶£çš„æ–°é—»")

        self.last_check = datetime.now()
        return interesting_news

    def get_summary(self) -> str:
        """è·å–ç›‘æ§æ‘˜è¦"""
        keywords = self.memory.get_all_keywords()
        return f"""
ğŸ“Š æ™ºèƒ½æ–°é—»ç›‘æ§åŠ©æ‰‹çŠ¶æ€
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ§  å…´è¶£å…³é”®è¯: {len(keywords)} ä¸ª
   ä¸»è¦å…´è¶£: {', '.join(list(self.memory.long_term_interests)[:5])}{'...' if len(self.memory.long_term_interests) > 5 else ''}

ğŸ” ç›‘æ§å¹³å°: çŸ¥ä¹ã€å¾®åšã€å“”å“©å“”å“©ã€æŠ–éŸ³ã€å¿«æ‰‹

â° ä¸Šæ¬¡æ£€æŸ¥: {self.last_check.strftime('%Y-%m-%d %H:%M:%S') if self.last_check else 'æœªè¿è¡Œ'}

ğŸ’¡ ä½¿ç”¨æç¤º:
   - è¯´"æ·»åŠ å…´è¶£: xxx" æ·»åŠ é•¿æœŸå…´è¶£
   - è¯´"å…³æ³¨: xxx" æ·»åŠ çŸ­æœŸå…³æ³¨
   - è¯´"æ£€æŸ¥æ–°é—»" ä¸»åŠ¨æ£€æŸ¥çƒ­ç‚¹
   - æˆ‘ä¼šè‡ªåŠ¨è®°ä½å¯¹è¯ä¸­çš„å…³é”®è¯
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        """.strip()


# CLI æµ‹è¯•å…¥å£
async def main():
    """æµ‹è¯•å…¥å£"""
    monitor = SmartNewsMonitor()

    print(monitor.get_summary())

    # æ£€æŸ¥æ–°é—»
    await monitor.check_and_notify()

    # äº¤äº’å¼æµ‹è¯•
    print("\nğŸ’¬ æ‚¨å¯ä»¥è¾“å…¥å‘½ä»¤:")
    print("  - æ·»åŠ å…´è¶£: <å…³é”®è¯>")
    print("  - å…³æ³¨: <å…³é”®è¯>")
    print("  - æ£€æŸ¥æ–°é—»")
    print("  - é€€å‡º")

    while True:
        cmd = input("\n> ").strip()
        if not cmd:
            continue

        if cmd in ["é€€å‡º", "exit", "quit"]:
            print("ğŸ‘‹ å†è§ï¼")
            break

        elif cmd.startswith("æ·»åŠ å…´è¶£:") or cmd.startswith("add interest:"):
            keyword = cmd.split(":", 1)[1].strip()
            monitor.add_interest(keyword, "long")

        elif cmd.startswith("å…³æ³¨:") or cmd.startswith("follow:"):
            keyword = cmd.split(":", 1)[1].strip()
            monitor.add_interest(keyword, "short")

        elif cmd in ["æ£€æŸ¥æ–°é—»", "check news", "æ–°é—»"]:
            await monitor.check_and_notify()

        elif cmd in ["çŠ¶æ€", "status", "summary"]:
            print(monitor.get_summary())

        else:
            # éšå¼å­¦ä¹ 
            monitor.learn_from_context(cmd)
            print(f"ğŸ§  å·²è®°å½•: {cmd}")


if __name__ == "__main__":
    asyncio.run(main())
