#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªç„¶è¯­è¨€æœç´¢æ¨¡å—
æ”¯æŒæ—¶é—´èŒƒå›´ã€æ–‡ä»¶ç±»å‹ã€ä¸»é¢˜ç­‰å¤šç»´åº¦æœç´¢
"""

import re
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from enum import Enum
import json


class QueryType(Enum):
    """æŸ¥è¯¢ç±»å‹"""
    TIME_BASED = "time_based"          # åŸºäºæ—¶é—´
    TOPIC_BASED = "topic_based"        # åŸºäºä¸»é¢˜
    FILE_TYPE_BASED = "file_type_based"  # åŸºäºæ–‡ä»¶ç±»å‹
    COMPLEX = "complex"                # å¤åˆæŸ¥è¯¢


@dataclass
class ParsedQuery:
    """è§£æåçš„æŸ¥è¯¢"""
    original: str                      # åŸå§‹æŸ¥è¯¢
    query_type: QueryType              # æŸ¥è¯¢ç±»å‹
    keywords: List[str]                # å…³é”®è¯
    time_range: Optional[Dict]         # æ—¶é—´èŒƒå›´
    file_types: Optional[List[str]]    # æ–‡ä»¶ç±»å‹
    topics: Optional[List[str]]        # ä¸»é¢˜
    filters: Dict[str, Any]            # å…¶ä»–è¿‡æ»¤æ¡ä»¶


class NaturalLanguageParser:
    """è‡ªç„¶è¯­è¨€æŸ¥è¯¢è§£æå™¨"""

    def __init__(self):
        """åˆå§‹åŒ–è§£æå™¨"""
        self.logger = logging.getLogger('NaturalLanguageParser')
        self._setup_patterns()

    def _setup_patterns(self):
        """è®¾ç½®åŒ¹é…æ¨¡å¼"""
        # æ—¶é—´æ¨¡å¼
        self.time_patterns = {
            'today': r'(ä»Šå¤©|ä»Šæ—¥)',
            'yesterday': r'(æ˜¨å¤©|æ˜¨æ—¥)',
            'this_week': r'(æœ¬å‘¨|è¿™å‘¨)',
            'last_week': r'(ä¸Šå‘¨|ä¸Šå‘¨)',
            'this_month': r'(æœ¬æœˆ|è¿™ä¸ªæœˆ)',
            'last_month': r'(ä¸Šæœˆ|ä¸Šä¸ªæœˆ)',
            'this_year': r'(ä»Šå¹´|ä»Šå¹´)',
            'recent_days': r'æœ€è¿‘(\d+)å¤©',
            'recent_weeks': r'æœ€è¿‘(\d+)å‘¨',
        }

        # æ–‡ä»¶ç±»å‹æ¨¡å¼
        self.file_type_patterns = {
            'python': r'(python|\.py)',
            'markdown': r'(markdown|\.md)',
            'yaml': r'(yaml|\.yml)',
            'json': r'(json|\.json)',
            'docx': r'(word|\.docx)',
            'pdf': r'(pdf|\.pdf)',
        }

        # ä¸»é¢˜æ¨¡å¼
        self.topic_patterns = {
            'ocr': r'(ocr|æ–‡å­—è¯†åˆ«|å›¾åƒè¯†åˆ«)',
            'ai': r'(ai|äººå·¥æ™ºèƒ½|æ™ºèƒ½)',
            'flask': r'(flask|web|ç½‘ç«™)',
            'database': r'(æ•°æ®åº“|sqlite|mysql)',
            'testing': r'(æµ‹è¯•|test)',
        }

    def parse(self, query: str) -> ParsedQuery:
        """
        è§£æè‡ªç„¶è¯­è¨€æŸ¥è¯¢

        Args:
            query: è‡ªç„¶è¯­è¨€æŸ¥è¯¢å­—ç¬¦ä¸²

        Returns:
            è§£æåçš„æŸ¥è¯¢å¯¹è±¡
        """
        self.logger.info(f"ğŸ” è§£ææŸ¥è¯¢: '{query}'")

        # æ ‡å‡†åŒ–æŸ¥è¯¢
        query = query.strip().lower()

        # æå–æ—¶é—´èŒƒå›´
        time_range = self._extract_time_range(query)

        # æå–æ–‡ä»¶ç±»å‹
        file_types = self._extract_file_types(query)

        # æå–ä¸»é¢˜
        topics = self._extract_topics(query)

        # æå–å…³é”®è¯
        keywords = self._extract_keywords(query)

        # ç¡®å®šæŸ¥è¯¢ç±»å‹
        query_type = self._determine_query_type(time_range, file_types, topics)

        # æ„å»ºè¿‡æ»¤æ¡ä»¶
        filters = {
            'time_range': time_range,
            'file_types': file_types,
            'topics': topics
        }

        parsed = ParsedQuery(
            original=query,
            query_type=query_type,
            keywords=keywords,
            time_range=time_range,
            file_types=file_types,
            topics=topics,
            filters=filters
        )

        self.logger.info(f"âœ… æŸ¥è¯¢è§£æå®Œæˆ: {query_type.value}")
        return parsed

    def _extract_time_range(self, query: str) -> Optional[Dict]:
        """æå–æ—¶é—´èŒƒå›´"""
        now = datetime.now()

        for pattern_name, pattern in self.time_patterns.items():
            match = re.search(pattern, query)
            if match:
                if pattern_name == 'today':
                    return {
                        'start': now.replace(hour=0, minute=0, second=0),
                        'end': now,
                        'label': 'ä»Šå¤©'
                    }
                elif pattern_name == 'yesterday':
                    yesterday = now - timedelta(days=1)
                    return {
                        'start': yesterday.replace(hour=0, minute=0, second=0),
                        'end': yesterday.replace(hour=23, minute=59, second=59),
                        'label': 'æ˜¨å¤©'
                    }
                elif pattern_name == 'this_week':
                    start_of_week = now - timedelta(days=now.weekday())
                    return {
                        'start': start_of_week.replace(hour=0, minute=0, second=0),
                        'end': now,
                        'label': 'æœ¬å‘¨'
                    }
                elif pattern_name == 'last_week':
                    start_of_this_week = now - timedelta(days=now.weekday())
                    start_of_last_week = start_of_this_week - timedelta(days=7)
                    return {
                        'start': start_of_last_week.replace(hour=0, minute=0, second=0),
                        'end': start_of_this_week - timedelta(seconds=1),
                        'label': 'ä¸Šå‘¨'
                    }
                elif pattern_name == 'recent_days':
                    days = int(match.group(1))
                    return {
                        'start': now - timedelta(days=days),
                        'end': now,
                        'label': f'æœ€è¿‘{days}å¤©'
                    }
                elif pattern_name == 'recent_weeks':
                    weeks = int(match.group(1))
                    return {
                        'start': now - timedelta(weeks=weeks),
                        'end': now,
                        'label': f'æœ€è¿‘{weeks}å‘¨'
                    }

        return None

    def _extract_file_types(self, query: str) -> Optional[List[str]]:
        """æå–æ–‡ä»¶ç±»å‹"""
        found_types = []

        for type_name, pattern in self.file_type_patterns.items():
            if re.search(pattern, query):
                found_types.append(type_name)

        return found_types if found_types else None

    def _extract_topics(self, query: str) -> Optional[List[str]]:
        """æå–ä¸»é¢˜"""
        found_topics = []

        for topic_name, pattern in self.topic_patterns.items():
            if re.search(pattern, query):
                found_topics.append(topic_name)

        return found_topics if found_topics else None

    def _extract_keywords(self, query: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç§»é™¤æ—¶é—´ã€æ–‡ä»¶ç±»å‹ã€ä¸»é¢˜ç›¸å…³çš„è¯
        cleaned = query

        for pattern in self.time_patterns.values():
            cleaned = re.sub(pattern, '', cleaned)

        for pattern in self.file_type_patterns.values():
            cleaned = re.sub(pattern, '', cleaned)

        for pattern in self.topic_patterns.values():
            cleaned = re.sub(pattern, '', cleaned)

        # ç§»é™¤å¸¸ç”¨åœç”¨è¯
        stop_words = ['çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ', 'ä¸', 'æˆ–', 'ç­‰']
        for word in stop_words:
            cleaned = cleaned.replace(word, ' ')

        # åˆ†è¯
        keywords = [k.strip() for k in cleaned.split() if k.strip()]

        return keywords

    def _determine_query_type(
        self,
        time_range: Optional[Dict],
        file_types: Optional[List[str]],
        topics: Optional[List[str]]
    ) -> QueryType:
        """ç¡®å®šæŸ¥è¯¢ç±»å‹"""
        has_time = time_range is not None
        has_type = file_types is not None
        has_topic = topics is not None

        conditions = [has_time, has_type, has_topic]
        true_count = sum(conditions)

        if true_count == 0:
            return QueryType.TOPIC_BASED
        elif true_count == 1:
            if has_time:
                return QueryType.TIME_BASED
            elif has_type:
                return QueryType.FILE_TYPE_BASED
            else:
                return QueryType.TOPIC_BASED
        else:
            return QueryType.COMPLEX


class EnhancedSearchEngine:
    """å¢å¼ºçš„æœç´¢å¼•æ“ - æ”¯æŒè‡ªç„¶è¯­è¨€æŸ¥è¯¢"""

    def __init__(self, base_search_engine=None):
        """
        åˆå§‹åŒ–æœç´¢å¼•æ“

        Args:
            base_search_engine: åŸºç¡€æœç´¢å¼•æ“ï¼ˆå¦‚è®°å¿†åŠ©æ‰‹çš„æœç´¢å¼•æ“ï¼‰
        """
        self.parser = NaturalLanguageParser()
        self.base_engine = base_search_engine
        self.logger = logging.getLogger('EnhancedSearchEngine')

    def search(self, query: str, top_k: int = 10) -> Dict[str, Any]:
        """
        è‡ªç„¶è¯­è¨€æœç´¢

        Args:
            query: è‡ªç„¶è¯­è¨€æŸ¥è¯¢
            top_k: è¿”å›ç»“æœæ•°é‡

        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        # è§£ææŸ¥è¯¢
        parsed = self.parser.parse(query)

        self.logger.info(f"ğŸ” æ‰§è¡Œæœç´¢: {parsed.query_type.value}")

        # æ‰§è¡Œæœç´¢
        if parsed.query_type == QueryType.TIME_BASED:
            results = self._search_by_time(parsed, top_k)
        elif parsed.query_type == QueryType.FILE_TYPE_BASED:
            results = self._search_by_file_type(parsed, top_k)
        elif parsed.query_type == QueryType.TOPIC_BASED:
            results = self._search_by_topic(parsed, top_k)
        else:  # COMPLEX
            results = self._search_complex(parsed, top_k)

        return {
            'query': query,
            'parsed': parsed,
            'results': results,
            'count': len(results)
        }

    def _search_by_time(self, parsed: ParsedQuery, top_k: int) -> List[Dict]:
        """æŒ‰æ—¶é—´èŒƒå›´æœç´¢"""
        # è¿™é‡Œå¯ä»¥é›†æˆæ–‡ä»¶ç³»ç»Ÿçš„æ—¶é—´è¿‡æ»¤
        # ç¤ºä¾‹ï¼šæœç´¢ç‰¹å®šæ—¶é—´èŒƒå›´å†…ä¿®æ”¹çš„æ–‡ä»¶

        results = []

        if self.base_engine:
            # ä½¿ç”¨åŸºç¡€æœç´¢å¼•æ“
            base_results = self.base_engine.search(' '.join(parsed.keywords))
            # åº”ç”¨æ—¶é—´è¿‡æ»¤
            results = self._filter_by_time(base_results, parsed.time_range)

        return results[:top_k]

    def _search_by_file_type(self, parsed: ParsedQuery, top_k: int) -> List[Dict]:
        """æŒ‰æ–‡ä»¶ç±»å‹æœç´¢"""
        results = []

        # ç¤ºä¾‹ï¼šæœç´¢ç‰¹å®šæ–‡ä»¶ç±»å‹
        for file_type in parsed.file_types:
            # è¿™é‡Œå¯ä»¥é›†æˆ Glob æœç´¢
            pass

        return results[:top_k]

    def _search_by_topic(self, parsed: ParsedQuery, top_k: int) -> List[Dict]:
        """æŒ‰ä¸»é¢˜æœç´¢"""
        results = []

        if self.base_engine:
            # ä½¿ç”¨åŸºç¡€æœç´¢å¼•æ“è¿›è¡Œè¯­ä¹‰æœç´¢
            query = ' '.join(parsed.keywords + (parsed.topics or []))
            results = self.base_engine.search(query)

        return results[:top_k]

    def _search_complex(self, parsed: ParsedQuery, top_k: int) -> List[Dict]:
        """å¤åˆæŸ¥è¯¢"""
        results = []

        # å…ˆæŒ‰ä¸»é¢˜æœç´¢
        topic_results = self._search_by_topic(parsed, top_k * 2)

        # å†åº”ç”¨å…¶ä»–è¿‡æ»¤æ¡ä»¶
        if parsed.time_range:
            topic_results = self._filter_by_time(topic_results, parsed.time_range)

        if parsed.file_types:
            topic_results = self._filter_by_file_type(topic_results, parsed.file_types)

        results = topic_results

        return results[:top_k]

    def _filter_by_time(self, results: List[Dict], time_range: Dict) -> List[Dict]:
        """æŒ‰æ—¶é—´è¿‡æ»¤ç»“æœ"""
        filtered = []
        start = time_range['start']
        end = time_range['end']

        for result in results:
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…ç»“æœç»“æ„æå–æ—¶é—´æˆ³
            # ç¤ºä¾‹å‡è®¾ç»“æœæœ‰ 'modified_time' å­—æ®µ
            if 'modified_time' in result:
                file_time = result['modified_time']
                if start <= file_time <= end:
                    filtered.append(result)

        return filtered

    def _filter_by_file_type(self, results: List[Dict], file_types: List[str]) -> List[Dict]:
        """æŒ‰æ–‡ä»¶ç±»å‹è¿‡æ»¤ç»“æœ"""
        filtered = []

        for result in results:
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…ç»“æœç»“æ„æå–æ–‡ä»¶ç±»å‹
            if 'file_path' in result:
                file_path = result['file_path']
                for ft in file_types:
                    if f'.{ft}' in file_path:
                        filtered.append(result)
                        break

        return filtered


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºæœç´¢å¼•æ“
    engine = EnhancedSearchEngine()

    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "ä¸Šå‘¨æ·»åŠ çš„ Python ç¬”è®°",
        "ä»Šå¤©å…³äº OCR çš„æ–‡æ¡£",
        "æœ€è¿‘7å¤©çš„ Flask ä»£ç ",
        "å…³äº AI çš„æ‰€æœ‰æ–‡ä»¶",
        "æœ¬å‘¨çš„ markdown æ–‡æ¡£"
    ]

    print("\n=== è‡ªç„¶è¯­è¨€æœç´¢æµ‹è¯• ===\n")

    for query in test_queries:
        print(f"\nğŸ” æŸ¥è¯¢: '{query}'")
        parsed = engine.parser.parse(query)

        print(f"  ç±»å‹: {parsed.query_type.value}")
        print(f"  å…³é”®è¯: {parsed.keywords}")
        print(f"  æ—¶é—´: {parsed.time_range}")
        print(f"  æ–‡ä»¶ç±»å‹: {parsed.file_types}")
        print(f"  ä¸»é¢˜: {parsed.topics}")

    print("\nâœ… è‡ªç„¶è¯­è¨€æœç´¢æ¨¡å—å·²åˆ›å»ºï¼")
