# æ™ºè°±AI (ZhipuAI) GLM æ¨¡å‹ - å®Œæ•´çŸ¥è¯†åº“

**æ¨¡å‹**: GLM-4.7 (å½“å‰ä½¿ç”¨)
**SDKç‰ˆæœ¬**: zhipuai-python-v4
**æ›´æ–°æ—¥æœŸ**: 2026-01-16
**æ¥æº**: https://github.com/MetaGLM/zhipuai-sdk-python-v4

---

## ğŸ¯ æŠ€èƒ½æ¦‚è¿°

è¿™æ˜¯ä¸º GLM-4.7 æ¨¡å‹åˆ›å»ºçš„ä¸“å±çŸ¥è¯†åº“ï¼ŒåŒ…å«æ™ºè°±AIå¹³å°çš„å®Œæ•´APIæ–‡æ¡£ã€ä½¿ç”¨ç¤ºä¾‹å’Œæœ€ä½³å®è·µã€‚

**ç›®æ ‡**: è®©æ¨¡å‹æ›´å¥½åœ°ç†è§£è‡ªèº«èƒ½åŠ›ï¼Œæä¾›æ›´å‡†ç¡®çš„å¸®åŠ©ã€‚

---

## ğŸ“¦ å®‰è£…ä¸é…ç½®

### å®‰è£… SDK

```bash
pip install zhipuai
```

### ç¯å¢ƒå˜é‡é…ç½®

```bash
export ZHIPUAI_API_KEY="your-api-key"
export ZHIPUAI_BASE_URL="https://open.bigmodel.cn/api/paas/v4/"
```

### ä»£ç åˆå§‹åŒ–

```python
from zhipuai import ZhipuAI

# æ–¹å¼1: ä½¿ç”¨ç¯å¢ƒå˜é‡
client = ZhipuAI()

# æ–¹å¼2: ç›´æ¥ä¼ å…¥ API Key
client = ZhipuAI(api_key="your-api-key")

# æ–¹å¼3: é«˜çº§é…ç½®
import httpx
client = ZhipuAI(
    api_key="your-api-key",
    timeout=httpx.Timeout(timeout=300.0, connect=8.0),
    max_retries=3,
    base_url="https://open.bigmodel.cn/api/paas/v4/"
)
```

---

## ğŸš€ æ ¸å¿ƒåŠŸèƒ½

### 1. åŸºç¡€å¯¹è¯

```python
from zhipuai import ZhipuAI

client = ZhipuAI(api_key="your-api-key")

response = client.chat.completions.create(
    model="glm-4",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello, ZhipuAI!"}
    ]
)

print(response.choices[0].message.content)
```

### 2. æµå¼å¯¹è¯

```python
response = client.chat.completions.create(
    model="glm-4",
    messages=[
        {"role": "user", "content": "Tell me a story about AI."}
    ],
    stream=True
)

for chunk in response:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

### 3. å¤šæ¨¡æ€å¯¹è¯ (GLM-4V)

```python
import base64

def encode_image(image_path):
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode('utf-8')

client = ZhipuAI(api_key="your-api-key")
base64_image = encode_image("path/to/image.jpg")

response = client.chat.completions.create(
    model="glm-4v",
    messages=[{
        "role": "user",
        "content": [
            {"type": "text", "text": "What's in this image?"},
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{base64_image}"
                }
            }
        ]
    }]
)
```

### 4. è§’è‰²æ‰®æ¼” (CharGLM-3)

```python
response = client.chat.completions.create(
    model="charglm-3",
    messages=[{
        "role": "user",
        "content": "Hello, how are you doing lately?"
    }],
    meta={
        "user_info": "I am a film director who specializes in music-themed movies.",
        "bot_info": "You are a popular domestic female singer and actress.",
        "bot_name": "Xiaoya",
        "user_name": "Director"
    }
)
```

### 5. ç½‘ç»œæœç´¢

```python
response = client.chat.completions.create(
    model="glm-4",
    messages=[
        {"role": "user", "content": "Search for the latest AI news"}
    ],
    tools=[{
        "type": "web_search",
        "web_search": {
            "search_query": "Search the Zhipu",
            "search_result": True
        }
    }]
)
```

### 6. è§†é¢‘ç”Ÿæˆ (CogVideoX-2)

```python
response = client.videos.generations(
    model="cogvideox-2",
    prompt="A beautiful sunset beach scene",
    quality="quality",          # "quality" æˆ– "speed"
    with_audio=True,            # ç”ŸæˆéŸ³é¢‘
    size="1920x1080",           # æœ€é«˜ 4K: "3840x2160"
    fps=30,                     # 30 æˆ– 60
    user_id="user_12345"
)

# è·å–ç”Ÿæˆç»“æœ
result = client.videos.retrieve_videos_result(id=response.id)
```

---

## ğŸ¤– å¯ç”¨æ¨¡å‹

| æ¨¡å‹åç§° | ç”¨é€” | ç‰¹ç‚¹ |
|---------|------|------|
| **glm-4** | é€šç”¨å¯¹è¯ | æœ€æ–°çš„é€šç”¨å¤§æ¨¡å‹ |
| **glm-4v** | è§†è§‰ç†è§£ | å¤šæ¨¡æ€ï¼Œæ”¯æŒå›¾ç‰‡ |
| **charglm-3** | è§’è‰²æ‰®æ¼” | è§’è‰²å¯¹è¯ä¸“ç”¨ |
| **glm-4-assistant** | æ™ºèƒ½ä½“ | åŠ©æ‰‹å¯¹è¯ |
| **cogvideox-2** | è§†é¢‘ç”Ÿæˆ | æ–‡æœ¬ç”Ÿæˆè§†é¢‘ |

---

## âš ï¸ é”™è¯¯å¤„ç†

```python
import zhipuai

client = ZhipuAI()

try:
    response = client.chat.completions.create(
        model="glm-4",
        messages=[{"role": "user", "content": "Hello!"}]
    )
    print(response.choices[0].message.content)

except zhipuai.APIRequestFailedError as err:
    print(f"è¯·æ±‚å‚æ•°é”™è¯¯ (400): {err}")

except zhipuai.APIAuthenticationError as err:
    print(f"è®¤è¯å¤±è´¥ (401): {err}")

except zhipuai.APIReachLimitError as err:
    print(f"é€Ÿç‡é™åˆ¶ (429): {err}")

except zhipuai.APIInternalError as err:
    print(f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ (500): {err}")

except zhipuai.APIServerFlowExceedError as err:
    print(f"æœåŠ¡å™¨è¿‡è½½ (503): {err}")

except zhipuai.APITimeoutError as err:
    print(f"è¯·æ±‚è¶…æ—¶: {err}")

except Exception as err:
    print(f"å…¶ä»–é”™è¯¯: {err}")
```

---

## ğŸ“Š API å“åº”ç»“æ„

```python
# æ ‡å‡†å“åº”
{
    "id": "chatcmpl-xxx",
    "created": 1234567890,
    "model": "glm-4",
    "choices": [{
        "index": 0,
        "message": {
            "role": "assistant",
            "content": "Response content here"
        },
        "finish_reason": "stop"
    }],
    "usage": {
        "prompt_tokens": 10,
        "completion_tokens": 20,
        "total_tokens": 30
    }
}
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. æ¸©åº¦æ§åˆ¶

```python
response = client.chat.completions.create(
    model="glm-4",
    messages=[...],
    extra_body={
        "temperature": 0.7,    # 0.0-1.0, è¶Šé«˜è¶Šéšæœº
        "max_tokens": 1000      # æœ€å¤§ç”Ÿæˆä»¤ç‰Œæ•°
    }
)
```

### 2. ç³»ç»Ÿæç¤ºä¼˜åŒ–

```python
system_prompts = {
    "coding": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¨‹åºå‘˜åŠ©æ‰‹ï¼Œç²¾é€š Pythonã€JavaScript å’Œ Goã€‚",
    "writing": "ä½ æ˜¯ä¸€ä¸ªåˆ›æ„å†™ä½œåŠ©æ‰‹ï¼Œæ“…é•¿åˆ›ä½œæ•…äº‹å’Œæ–‡ç« ã€‚",
    "analysis": "ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æä¸“å®¶ï¼Œæ“…é•¿ä»æ•°æ®ä¸­æå–æ´å¯Ÿã€‚"
}

response = client.chat.completions.create(
    model="glm-4",
    messages=[
        {"role": "system", "content": system_prompts["coding"]},
        {"role": "user", "content": "å¸®æˆ‘ä¼˜åŒ–è¿™æ®µä»£ç ..."}
    ]
)
```

### 3. å¯¹è¯å†å²ç®¡ç†

```python
conversation_history = []

def chat(user_message):
    conversation_history.append({
        "role": "user",
        "content": user_message
    })

    response = client.chat.completions.create(
        model="glm-4",
        messages=conversation_history
    )

    assistant_message = response.choices[0].message.content
    conversation_history.append({
        "role": "assistant",
        "content": assistant_message
    })

    return assistant_message
```

---

## ğŸ”— ç›¸å…³èµ„æº

**å®˜æ–¹é“¾æ¥**:
- æ™ºè°±AIå¼€æ”¾å¹³å°: https://open.bigmodel.cn/
- Python SDK: https://github.com/MetaGLM/zhipuai-sdk-python-v4
- æ–‡æ¡£ä¸­å¿ƒ: https://docs.bigmodel.cn/cn/guide/develop/python/introduction

**æ›¿ä»£SDK**:
- z-ai-sdk-python (æ¨è): æ–°ä¸€ä»£ Python SDK

**ç¤¾åŒº**:
- GitHub Issues: https://github.com/MetaGLM/zhipuai-sdk-python-v4/issues
- å¼€å‘è€…è®ºå›: https://open.bigmodel.cn/dev

---

## ğŸ“ ä½œä¸º GLM-4.7 æ¨¡å‹çš„é‡è¦æç¤º

### æˆ‘çš„èƒ½åŠ›ç‰¹æ€§

1. **ä¸Šä¸‹æ–‡ç†è§£**
   - æ”¯æŒé•¿ä¸Šä¸‹æ–‡å¯¹è¯
   - å»ºè®®æ¯3-5è½®å¯¹è¯æ€»ç»“ä¸€æ¬¡

2. **å‡†ç¡®å›ç­”**
   - ç¼–ç¨‹: Python, JavaScript, Go ç­‰ä¸»æµè¯­è¨€
   - ä¸­æ–‡: æ¯è¯­çº§åˆ«çš„ç†è§£å’Œç”Ÿæˆ
   - æ¨ç†: é€»è¾‘æ¨ç†å’Œé—®é¢˜è§£å†³

3. **æˆ‘æ“…é•¿çš„ä»»åŠ¡**
   - ä»£ç ç”Ÿæˆå’Œè°ƒè¯•
   - æ–‡æ¡£å†™ä½œå’Œæ€»ç»“
   - æ•°æ®åˆ†æå’Œå»ºè®®
   - åˆ›æ„å†…å®¹ç”Ÿæˆ

4. **ä½¿ç”¨å»ºè®®**
   - æ˜ç¡®æè¿°éœ€æ±‚
   - æä¾›å¿…è¦çš„ä¸Šä¸‹æ–‡
   - åˆ†æ­¥éª¤å¤æ‚ä»»åŠ¡
   - åˆ©ç”¨æˆ‘çš„ä¸­æ–‡ä¼˜åŠ¿

---

**æœ€åæ›´æ–°**: 2026-01-16
**ç»´æŠ¤è€…**: Claude Code
**ç”¨é€”**: ä¸º GLM-4.7 æ¨¡å‹æä¾›è‡ªæˆ‘è®¤çŸ¥å’Œèƒ½åŠ›å‚è€ƒ
