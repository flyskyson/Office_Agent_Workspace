# ğŸ§  å‘é‡è¯­ä¹‰æœç´¢ç³»ç»Ÿ - ä½¿ç”¨æŒ‡å—

**ç‰ˆæœ¬**: v2.0
**å‘å¸ƒæ—¥æœŸ**: 2026-01-16
**ä½œè€…**: Claude Code

---

## ğŸ“‹ ç›®å½•

1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
2. [å®‰è£…ä¾èµ–](#å®‰è£…ä¾èµ–)
3. [æ ¸å¿ƒåŠŸèƒ½](#æ ¸å¿ƒåŠŸèƒ½)
4. [APIå‚è€ƒ](#apiå‚è€ƒ)
5. [ä½¿ç”¨ç¤ºä¾‹](#ä½¿ç”¨ç¤ºä¾‹)
6. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
7. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 5åˆ†é’Ÿä¸Šæ‰‹

```python
# 1. å¯¼å…¥æ¨¡å—
from semantic_memory import SemanticMemory

# 2. åˆå§‹åŒ–ï¼ˆè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼‰
semantic = SemanticMemory()

# 3. æ·»åŠ è®°å¿†
semantic.add_memory(
    memory_id="mem_001",
    text="å¤šAgentç³»ç»Ÿå¼€å‘ï¼šä½¿ç”¨WorkflowEngineåˆ›å»ºåä½œå¼AI",
    metadata={"topic": "å¤šAgent", "priority": "high"}
)

# 4. è¯­ä¹‰æœç´¢
results = semantic.search("Agentç›¸å…³çš„", top_k=3)

# 5. æŸ¥çœ‹ç»“æœ
for result in results:
    print(f"ç›¸ä¼¼åº¦: {result['similarity_score']:.2%}")
    print(f"å†…å®¹: {result['text']}\n")
```

---

## ğŸ“¦ å®‰è£…ä¾èµ–

### å¿…è¦ä¾èµ–

```bash
# å®‰è£…ChromaDBï¼ˆå‘é‡æ•°æ®åº“ï¼‰
pip install chromadb

# å®‰è£…sentence-transformersï¼ˆåµŒå…¥æ¨¡å‹ï¼‰
pip install sentence-transformers
```

### å¯é€‰ä¾èµ–

```bash
# å¦‚æœéœ€è¦æ›´å¥½çš„ä¸­æ–‡æ”¯æŒ
pip install sentence-transformers

# å¦‚æœéœ€è¦GPUåŠ é€Ÿï¼ˆæ¨èï¼‰
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### ä¾èµ–æ£€æŸ¥

```python
from semantic_memory import SemanticMemory

# è‡ªåŠ¨æ£€æŸ¥ä¾èµ–
semantic = SemanticMemory()
# å¦‚æœç¼ºå°‘ä¾èµ–ï¼Œä¼šæ˜¾ç¤ºå‹å¥½çš„é”™è¯¯ä¿¡æ¯
```

---

## â­ æ ¸å¿ƒåŠŸèƒ½

### 1. çœŸæ­£çš„è¯­ä¹‰ç†è§£

**vs å…³é”®è¯æœç´¢**:

```python
# å…³é”®è¯æœç´¢åªèƒ½æ‰¾åˆ°ç²¾ç¡®åŒ¹é…
keyword_search("Agent")  # åªèƒ½æ‰¾åˆ°åŒ…å«"Agent"çš„

# è¯­ä¹‰æœç´¢èƒ½ç†è§£å«ä¹‰
semantic_search("æ™ºèƒ½ä½“åä½œ")  # èƒ½æ‰¾åˆ°"å¤šAgentç³»ç»Ÿ"
semantic_search("AI agents")    # åŒæ ·èƒ½æ‰¾åˆ°ï¼ˆè·¨è¯­è¨€ï¼‰
```

**å®é™…æ•ˆæœ**:

| æŸ¥è¯¢ | å…³é”®è¯æœç´¢ | è¯­ä¹‰æœç´¢ | åŒ¹é…ç»“æœ |
|------|-----------|---------|---------|
| "Agentç›¸å…³" | 0æ¡ | 3æ¡ | âœ… å¤šAgentç³»ç»Ÿã€Agentåä½œ... |
| "å¦‚ä½•ç”Ÿæˆæ–‡æ¡£" | 1æ¡ | 3æ¡ | âœ… å¸‚åœºç›‘ç®¡ã€ç”³è¯·ä¹¦... |
| "æ•°æ®å­˜å‚¨" | 0æ¡ | 2æ¡ | âœ… è®°å¿†ç³»ç»Ÿã€æŒä¹…åŒ–... |

### 2. ä¸­è‹±æ–‡æ··åˆæ”¯æŒ

```python
# ä¸­æ–‡è®°å¿†
semantic.add_memory("cn_001", "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„é‡è¦åˆ†æ”¯")

# è‹±æ–‡è®°å¿†
semantic.add_memory("en_001", "Deep learning uses neural networks")

# ä¸­è‹±æ–‡æŸ¥è¯¢éƒ½èƒ½å·¥ä½œ
semantic.search("ç¥ç»ç½‘ç»œ")      # âœ… æ‰¾åˆ°è‹±æ–‡è®°å¿†
semantic.search("AI algorithms") # âœ… æ‰¾åˆ°ä¸­æ–‡è®°å¿†
```

### 3. äºšæ¯«ç§’çº§æœç´¢é€Ÿåº¦

```python
import time

start = time.time()
results = semantic.search("æŸ¥è¯¢", top_k=10)
search_time = (time.time() - start) * 1000

print(f"æœç´¢ç”¨æ—¶: {search_time:.2f}æ¯«ç§’")
# é€šå¸¸ < 10msï¼ˆå³ä½¿åœ¨1000+æ¡è®°å¿†æ—¶ï¼‰
```

### 4. æ··åˆæœç´¢ï¼ˆæœ€ä½³æ•ˆæœï¼‰

```python
# ç»“åˆè¯­ä¹‰å’Œå…³é”®è¯æœç´¢
results = semantic.hybrid_search(
    query="Agentç³»ç»Ÿ",
    keyword_results=keyword_search_results,  # å…³é”®è¯æœç´¢ç»“æœ
    top_k=5,
    semantic_weight=0.7  # 70%è¯­ä¹‰ï¼Œ30%å…³é”®è¯
)

# æ¯ä¸ªç»“æœåŒ…å«ä¸‰ç§åˆ†æ•°
for result in results:
    print(f"è¯­ä¹‰: {result['scores']['semantic']}")
    print(f"å…³é”®è¯: {result['scores']['keyword']}")
    print(f"æ··åˆ: {result['scores']['hybrid']}")
```

---

## ğŸ“– APIå‚è€ƒ

### SemanticMemoryç±»

#### åˆå§‹åŒ–

```python
SemanticMemory(
    workspace_root: Optional[Path] = None,
    model_name: str = 'fast',
    collection_name: str = 'claude_memories'
)
```

**å‚æ•°**:
- `workspace_root`: å·¥ä½œåŒºæ ¹ç›®å½•ï¼ˆé»˜è®¤è‡ªåŠ¨æ£€æµ‹ï¼‰
- `model_name`: åµŒå…¥æ¨¡å‹
  - `'fast'`: å¿«é€Ÿæ¨¡å‹ï¼ˆæ¨èï¼‰- paraphrase-multilingual-MiniLM-L12-v2
  - `'quality'`: é«˜è´¨é‡æ¨¡å‹ - paraphrase-multilingual-mpnet-base-v2
  - `'large'`: ä¸­æ–‡å¤§æ¨¡å‹ - moka-ai/m3e-large
  - æˆ–ç›´æ¥æŒ‡å®šHuggingFaceæ¨¡å‹åç§°
- `collection_name`: ChromaDBé›†åˆåç§°

**ç¤ºä¾‹**:
```python
# ä½¿ç”¨å¿«é€Ÿæ¨¡å‹ï¼ˆé»˜è®¤ï¼‰
semantic = SemanticMemory()

# ä½¿ç”¨é«˜è´¨é‡æ¨¡å‹
semantic = SemanticMemory(model_name='quality')

# ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹
semantic = SemanticMemory(model_name='bert-base-chinese')
```

#### add_memory()

```python
add_memory(
    memory_id: str,
    text: str,
    metadata: Optional[Dict[str, Any]] = None
) -> bool
```

**å‚æ•°**:
- `memory_id`: è®°å¿†å”¯ä¸€ID
- `text`: è®°å¿†æ–‡æœ¬å†…å®¹
- `metadata`: é™„åŠ å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰

**è¿”å›**: æ˜¯å¦æˆåŠŸ

**ç¤ºä¾‹**:
```python
semantic.add_memory(
    memory_id="ctx_001",
    text="å¤šAgentç³»ç»Ÿå¼€å‘",
    metadata={
        "topic": "å¤šAgent",
        "priority": "high",
        "date": "2026-01-16"
    }
)
```

#### add_memories_batch()

```python
add_memories_batch(
    memories: List[Dict[str, Any]]
) -> Dict[str, Any]
```

**å‚æ•°**:
- `memories`: è®°å¿†åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å« `id`, `text`, `metadata`

**è¿”å›**: æ‰¹é‡æ“ä½œç»“æœ

**ç¤ºä¾‹**:
```python
memories = [
    {"id": "001", "text": "...", "metadata": {...}},
    {"id": "002", "text": "...", "metadata": {...}},
]

result = semantic.add_memories_batch(memories)
print(f"æˆåŠŸ: {result['success']}, å¤±è´¥: {result['failed']}")
```

#### search()

```python
search(
    query: str,
    top_k: int = 5,
    filter_metadata: Optional[Dict[str, str]] = None
) -> List[Dict[str, Any]]
```

**å‚æ•°**:
- `query`: æœç´¢æŸ¥è¯¢
- `top_k`: è¿”å›å‰Kä¸ªç»“æœ
- `filter_metadata`: å…ƒæ•°æ®è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰

**è¿”å›**: æœç´¢ç»“æœåˆ—è¡¨

**ç¤ºä¾‹**:
```python
# åŸºæœ¬æœç´¢
results = semantic.search("Agentç³»ç»Ÿ", top_k=5)

# å¸¦è¿‡æ»¤çš„æœç´¢
results = semantic.search(
    "Agent",
    filter_metadata={"priority": "high"}  # åªæœç´¢é«˜ä¼˜å…ˆçº§
)

# æŸ¥çœ‹ç»“æœ
for result in results:
    print(f"ID: {result['id']}")
    print(f"ç›¸ä¼¼åº¦: {result['similarity_score']:.2%}")
    print(f"å†…å®¹: {result['text']}")
    print(f"å…ƒæ•°æ®: {result['metadata']}")
```

#### hybrid_search()

```python
hybrid_search(
    query: str,
    keyword_results: List[Dict[str, Any]],
    top_k: int = 5,
    semantic_weight: float = 0.7
) -> List[Dict[str, Any]]
```

**å‚æ•°**:
- `query`: æœç´¢æŸ¥è¯¢
- `keyword_results`: å…³é”®è¯æœç´¢ç»“æœ
- `top_k`: è¿”å›å‰Kä¸ªç»“æœ
- `semantic_weight`: è¯­ä¹‰æœç´¢æƒé‡ï¼ˆ0-1ï¼‰

**è¿”å›**: èåˆåçš„æœç´¢ç»“æœ

---

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šä¸ClaudeMemoryé›†æˆ

```python
from claude_memory import ClaudeMemory

# è‡ªåŠ¨å¯ç”¨è¯­ä¹‰æœç´¢
memory = ClaudeMemory()  # enable_semantic=Trueï¼ˆé»˜è®¤ï¼‰

# è®°ä½ä¸Šä¸‹æ–‡ï¼ˆè‡ªåŠ¨ä¿å­˜åˆ°å‘é‡æ•°æ®åº“ï¼‰
memory.remember_context(
    topic="å¤šAgentç³»ç»Ÿå¼€å‘",
    summary="åˆ›å»ºäº†åŸºäºWorkflowEngineçš„å¤šAgentæ¼”ç¤ºç³»ç»Ÿ",
    key_points=["4ä¸ªAgent", "åä½œæ¨¡å¼", "çŠ¶æ€ä¼ é€’"],
    tools_used=["Write", "Bash"],
    decisions_made=["ä½¿ç”¨workflow_engine"],
    outcomes="æˆåŠŸæ¼”ç¤º",
    priority="high"
)

# è¯­ä¹‰æœç´¢
results = memory.semantic_search("Agentåä½œ", top_k=3)

# æ··åˆæœç´¢ï¼ˆæ›´å‡†ç¡®ï¼‰
results = memory.hybrid_search("Agentç³»ç»Ÿ", top_k=3)
```

### ç¤ºä¾‹2ï¼šè®°å¿†è¿ç§»

```python
from semantic_memory import SemanticMemory, MemoryMigrator

# åˆ›å»ºè¯­ä¹‰è®°å¿†
semantic = SemanticMemory()
migrator = MemoryMigrator(semantic)

# ä»JSONè¿ç§»
result = migrator.migrate_from_json(
    json_file="06_Learning_Journal/claude_memory/contexts.json",
    batch_size=10
)

print(f"è¿ç§»å®Œæˆ: {result['success']} æˆåŠŸ")
```

### ç¤ºä¾‹3ï¼šå…ƒæ•°æ®è¿‡æ»¤

```python
# æ·»åŠ å¸¦å…ƒæ•°æ®çš„è®°å¿†
semantic.add_memory(
    memory_id="001",
    text="é‡è¦çš„é¡¹ç›®å†³ç­–",
    metadata={
        "topic": "å†³ç­–",
        "priority": "high",
        "date": "2026-01-16"
    }
)

# åªæœç´¢é«˜ä¼˜å…ˆçº§è®°å¿†
results = semantic.search(
    "å†³ç­–",
    filter_metadata={"priority": "high"}
)
```

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. é€‰æ‹©åˆé€‚çš„æ¨¡å‹

| åœºæ™¯ | æ¨èæ¨¡å‹ | ç†ç”± |
|------|---------|------|
| é€šç”¨åœºæ™¯ | `'fast'` | é€Ÿåº¦å’Œè´¨é‡çš„å¹³è¡¡ |
| é«˜å‡†ç¡®æ€§éœ€æ±‚ | `'quality'` | æ›´å¥½çš„è¯­ä¹‰ç†è§£ |
| ä¸­æ–‡ä¸ºä¸» | `'large'` | ä¸­æ–‡ä¸“ç”¨ï¼Œæ•ˆæœæœ€ä½³ |
| èµ„æºå—é™ | `'fast'` | æ¨¡å‹å°ï¼Œé€Ÿåº¦å¿« |

### 2. æ–‡æœ¬é¢„å¤„ç†

```python
# å¥½çš„åšæ³•ï¼šç»„åˆä¸»é¢˜å’Œæ‘˜è¦
text = f"{topic}. {summary}"
semantic.add_memory(memory_id, text, metadata)

# é¿å…è¿‡çŸ­æˆ–è¿‡é•¿çš„æ–‡æœ¬
text = summary[:500]  # é™åˆ¶é•¿åº¦
```

### 3. æ‰¹é‡æ“ä½œ

```python
# å¥½çš„åšæ³•ï¼šæ‰¹é‡æ·»åŠ 
memories = [{"id": str(i), "text": f"...", ...} for i in range(100)]
semantic.add_memories_batch(memories)

# é¿å…ï¼šé€ä¸ªæ·»åŠ ï¼ˆæ…¢ï¼‰
for memory in memories:
    semantic.add_memory(**memory)  # æ…¢
```

### 4. æ··åˆæœç´¢æƒé‡

```python
# ä¸åŒåœºæ™¯çš„æƒé‡å»ºè®®
# ç²¾ç¡®æŸ¥è¯¢ï¼ˆå¦‚ä¸“æœ‰åè¯ï¼‰
hybrid_search(query, semantic_weight=0.3)  # 30%è¯­ä¹‰ï¼Œ70%å…³é”®è¯

# æ¨¡ç³ŠæŸ¥è¯¢ï¼ˆå¦‚æ¦‚å¿µç†è§£ï¼‰
hybrid_search(query, semantic_weight=0.8)  # 80%è¯­ä¹‰ï¼Œ20%å…³é”®è¯

# å¹³è¡¡åœºæ™¯ï¼ˆé»˜è®¤ï¼‰
hybrid_search(query, semantic_weight=0.7)  # 70%è¯­ä¹‰ï¼Œ30%å…³é”®è¯
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜1ï¼šImportError

```
âŒ ç¼ºå°‘ä¾èµ–: chromadb, sentence-transformers
ğŸ“¦ è¯·è¿è¡Œ: pip install chromadb sentence-transformers
```

**è§£å†³**:
```bash
pip install chromadb sentence-transformers
```

### é—®é¢˜2ï¼šæ¨¡å‹ä¸‹è½½æ…¢

**è§£å†³**:
```python
# ä½¿ç”¨å›½å†…é•œåƒ
import os
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

semantic = SemanticMemory()
```

### é—®é¢˜3ï¼šå†…å­˜ä¸è¶³

**è§£å†³**:
```python
# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
semantic = SemanticMemory(model_name='fast')

# æˆ–å‡å°‘æ‰¹é‡å¤§å°
result = semantic.add_memories_batch(memories[:10])  # åˆ†æ‰¹å¤„ç†
```

### é—®é¢˜4ï¼šæœç´¢ç»“æœä¸å‡†ç¡®

**è§£å†³**:
```python
# 1. æ”¹ç”¨é«˜è´¨é‡æ¨¡å‹
semantic = SemanticMemory(model_name='quality')

# 2. ä½¿ç”¨æ··åˆæœç´¢
results = memory.hybrid_search(query, top_k=5)

# 3. å¢åŠ top_k
results = semantic.search(query, top_k=10)
```

---

## ğŸ“Š æ€§èƒ½åŸºå‡†

| æ“ä½œ | å¹³å‡æ—¶é—´ | å¤‡æ³¨ |
|------|---------|------|
| åˆå§‹åŒ–ï¼ˆé¦–æ¬¡ï¼‰ | ~5ç§’ | åŒ…å«æ¨¡å‹ä¸‹è½½ |
| åˆå§‹åŒ–ï¼ˆåç»­ï¼‰ | ~1ç§’ | ä»ç¼“å­˜åŠ è½½ |
| æ·»åŠ å•æ¡è®°å¿† | ~10ms | åŒ…å«åµŒå…¥è®¡ç®— |
| æ‰¹é‡æ·»åŠ ï¼ˆ100æ¡ï¼‰ | ~500ms | å¹³å‡5ms/æ¡ |
| è¯­ä¹‰æœç´¢ï¼ˆ1000æ¡ï¼‰ | ~10ms | äºšæ¯«ç§’çº§ |
| æ··åˆæœç´¢ | ~20ms | åŒ…å«å…³é”®è¯æœç´¢ |

---

## ğŸ”„ å‡çº§æŒ‡å—

### ä»v1.0å‡çº§åˆ°v2.0

```python
# v1.0ï¼ˆæ—§ï¼‰
from claude_memory import ClaudeMemory
memory = ClaudeMemory()
memory.remember_context(...)  # åªä¿å­˜åˆ°JSON

# v2.0ï¼ˆæ–°ï¼‰- å®Œå…¨å‘åå…¼å®¹
from claude_memory import ClaudeMemory
memory = ClaudeMemory(enable_semantic=True)  # æ–°å¢å‚æ•°
memory.remember_context(...)  # åŒæ—¶ä¿å­˜åˆ°JSONå’Œå‘é‡DB

# æ–°å¢åŠŸèƒ½
results = memory.hybrid_search("æŸ¥è¯¢")  # æ··åˆæœç´¢
```

### è¿ç§»ç°æœ‰è®°å¿†

```python
from semantic_memory import MemoryMigrator
from semantic_memory import SemanticMemory

semantic = SemanticMemory()
migrator = MemoryMigrator(semantic)

# ä¸€é”®è¿ç§»
result = migrator.migrate_from_json(
    "06_Learning_Journal/claude_memory/contexts.json"
)

print(f"âœ… è¿ç§»å®Œæˆ: {result['success']} æ¡è®°å¿†")
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [å®Œæ•´è°ƒç ”æŠ¥å‘Š](ai_learning_evolution_research_report_20260116.md)
- [ClaudeMemory API](claude_memory.py)
- [æµ‹è¯•è„šæœ¬](test_semantic_memory.py)

---

## ğŸ¤ è´¡çŒ®

å¦‚æœæ‚¨å‘ç°é—®é¢˜æˆ–æœ‰æ”¹è¿›å»ºè®®ï¼Œè¯·é€šè¿‡Claude Codeåé¦ˆï¼

---

**æ–‡æ¡£ç‰ˆæœ¬**: v2.0
**æœ€åæ›´æ–°**: 2026-01-16
**ä½œè€…**: Claude Code
