#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®°å¿†è¿ç§»å·¥å…· - å°†ç°æœ‰JSONè®°å¿†è¿ç§»åˆ°å‘é‡æ•°æ®åº“

ä½œè€…: Claude Code
æ—¥æœŸ: 2026-01-16
"""

import sys
import os
from pathlib import Path

# Windows ç»ˆç«¯ç¼–ç ä¿®å¤
if sys.platform == 'win32':
    try:
        import codecs
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')
    except:
        pass

# è®¾ç½®å›½å†…é•œåƒ
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "00_Agent_Library"))

from semantic_memory import SemanticMemory, MemoryMigrator


def main():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                    â•‘
â•‘              è®°å¿†è¿ç§»å·¥å…· - JSONåˆ°å‘é‡æ•°æ®åº“                        â•‘
â•‘                                                                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    # åˆå§‹åŒ–è¯­ä¹‰è®°å¿†
    print("\nğŸ”„ åˆå§‹åŒ–è¯­ä¹‰è®°å¿†ç³»ç»Ÿ...")
    semantic = SemanticMemory()
    migrator = MemoryMigrator(semantic)

    # è·å–contexts.jsonè·¯å¾„
    contexts_file = (project_root / "06_Learning_Journal" / "claude_memory" / "contexts.json")

    if not contexts_file.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {contexts_file}")
        return False

    print(f"ğŸ“‚ è¯»å–: {contexts_file}")

    # æ˜¾ç¤ºå½“å‰çŠ¶æ€
    import json
    with open(contexts_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    total_contexts = data.get('total_contexts', 0)
    print(f"ğŸ“Š ç°æœ‰è®°å¿†æ•°: {total_contexts}")

    # æ‰§è¡Œè¿ç§»
    print("\nğŸš€ å¼€å§‹è¿ç§»...")
    print("-" * 70)

    result = migrator.migrate_from_json(contexts_file, batch_size=10)

    # æ˜¾ç¤ºç»“æœ
    print("\n" + "=" * 70)
    print("ğŸ“Š è¿ç§»ç»“æœ")
    print("=" * 70)
    print(f"âœ… æ€»æ•°: {result.get('total', 0)}")
    print(f"âœ… æˆåŠŸ: {result.get('success', 0)}")
    print(f"âŒ å¤±è´¥: {result.get('failed', 0)}")

    # æ˜¾ç¤ºç»Ÿè®¡
    stats = semantic.get_stats()
    print(f"\nğŸ“Š å‘é‡æ•°æ®åº“ç»Ÿè®¡:")
    print(f"   è®°å¿†æ€»æ•°: {stats['total_memories']}")
    print(f"   æ¨¡å‹: {stats['model_name']}")

    # éªŒè¯æœç´¢
    print("\n" + "=" * 70)
    print("ğŸ” éªŒè¯è¯­ä¹‰æœç´¢")
    print("=" * 70)

    test_queries = [
        "Agentç›¸å…³",
        "å·¥ä½œåŒºçŠ¶æ€",
        "è§’è‰²å®šä¹‰",
        "è®°å¿†ç³»ç»Ÿ"
    ]

    for query in test_queries:
        results = semantic.search(query, top_k=2)
        print(f"\nğŸ’­ æŸ¥è¯¢: '{query}'")
        if results:
            for i, r in enumerate(results, 1):
                print(f"   {i}. {r['similarity_score']:.2%} - {r['text'][:60]}...")
        else:
            print("   âš ï¸ æœªæ‰¾åˆ°ç»“æœ")

    print("\n" + "=" * 70)
    print("ğŸ‰ è¿ç§»å®Œæˆï¼æ‰€æœ‰è®°å¿†ç°åœ¨æ”¯æŒè¯­ä¹‰æœç´¢")
    print("=" * 70)

    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
